diff --git a/Documentation/devicetree/bindings/spi/spi-cadence.yaml b/Documentation/devicetree/bindings/spi/spi-cadence.yaml
new file mode 100644
index 000000000..9787be213
--- /dev/null
+++ b/Documentation/devicetree/bindings/spi/spi-cadence.yaml
@@ -0,0 +1,66 @@
+# SPDX-License-Identifier: (GPL-2.0-only OR BSD-2-Clause)
+%YAML 1.2
+---
+$id: http://devicetree.org/schemas/spi/spi-cadence.yaml#
+$schema: http://devicetree.org/meta-schemas/core.yaml#
+
+title: Cadence SPI controller Device Tree Bindings
+
+maintainers:
+  - Michal Simek <michal.simek@xilinx.com>
+
+allOf:
+  - $ref: "spi-controller.yaml#"
+
+properties:
+  compatible:
+    enum:
+      - cdns,spi-r1p6
+      - xlnx,zynq-spi-r1p6
+
+  reg:
+    maxItems: 1
+
+  interrupts:
+    maxItems: 1
+
+  clock-names:
+    items:
+      - const: ref_clk
+      - const: pclk
+
+  clocks:
+    maxItems: 2
+
+  num-cs:
+    description: |
+      Number of chip selects used. If a decoder is used,
+      this will be the number of chip selects after the
+      decoder.
+    $ref: /schemas/types.yaml#/definitions/uint32
+    minimum: 1
+    maximum: 4
+    default: 4
+
+  is-decoded-cs:
+    description: |
+      Flag to indicate whether decoder is used or not.
+    $ref: /schemas/types.yaml#/definitions/uint32
+    enum: [ 0, 1 ]
+    default: 0
+
+unevaluatedProperties: false
+
+examples:
+  - |
+    spi@e0007000 {
+      compatible = "xlnx,zynq-spi-r1p6";
+      clock-names = "ref_clk", "pclk";
+      clocks = <&clkc 26>, <&clkc 35>;
+      interrupt-parent = <&intc>;
+      interrupts = <0 49 4>;
+      num-cs = <4>;
+      is-decoded-cs = <0>;
+      reg = <0xe0007000 0x1000>;
+    };
+...
diff --git a/Documentation/devicetree/bindings/spi/spi-xilinx.txt b/Documentation/devicetree/bindings/spi/spi-xilinx.txt
index 5f4ed3e5c..0dd14a88c 100644
--- a/Documentation/devicetree/bindings/spi/spi-xilinx.txt
+++ b/Documentation/devicetree/bindings/spi/spi-xilinx.txt
@@ -6,18 +6,31 @@ Required properties:
 - reg			: Physical base address and size of SPI registers map.
 - interrupts		: Property with a value describing the interrupt
 			  number.
+- fifo-size		: Depth of TX/RX Fifos
 
 Optional properties:
 - xlnx,num-ss-bits	 : Number of chip selects used.
 - xlnx,num-transfer-bits : Number of bits per transfer. This will be 8 if not specified
+- num-cs		: Number of chip selects used.
+- bits-per-word		: Number of bits per word.
+- clock-names		: Can be one or more strings from "axi_clk", "axi4_clk"
+			  and "spi_clk" depending on IP configurations.
+- clocks		: Input clock specifier. Refer to common clock bindings.
+- xlnx,startup-block	: Indicates whether startup block is enabled or disabled.
 
 Example:
 	axi_quad_spi@41e00000 {
 			compatible = "xlnx,xps-spi-2.00.a";
+			clock-names = "axi_clk", "axi4_clk", "spi_clk";
+			clocks = <&clkc 71>, <&clkc 72>, <&clkc 73>;
 			interrupt-parent = <&intc>;
 			interrupts = <0 31 1>;
 			reg = <0x41e00000 0x10000>;
 			xlnx,num-ss-bits = <0x1>;
 			xlnx,num-transfer-bits = <32>;
+			num-cs = <0x1>;
+			fifo-size = <256>;
+			bits-per-word = <8>;
+			xlnx,startup-block;
 	};
 
diff --git a/Documentation/devicetree/bindings/spi/spi-zynqmp-qspi.txt b/Documentation/devicetree/bindings/spi/spi-zynqmp-qspi.txt
index 0f6d37ff5..a40827f58 100644
--- a/Documentation/devicetree/bindings/spi/spi-zynqmp-qspi.txt
+++ b/Documentation/devicetree/bindings/spi/spi-zynqmp-qspi.txt
@@ -2,7 +2,8 @@ Xilinx Zynq UltraScale+ MPSoC GQSPI controller Device Tree Bindings
 -------------------------------------------------------------------
 
 Required properties:
-- compatible		: Should be "xlnx,zynqmp-qspi-1.0".
+- compatible		: Should be "xlnx,zynqmp-qspi-1.0" for zynqmp or
+			  "xlnx,versal-qspi-1.0" for versal.
 - reg			: Physical base address and size of GQSPI registers map.
 - interrupts		: Property with a value describing the interrupt
 			  number.
@@ -12,6 +13,14 @@ Required properties:
 
 Optional properties:
 - num-cs		: Number of chip selects used.
+- has-io-mode		: boolean property describes the controller operating
+			  mode. if exists controller will operate in IO mode
+			  else dma mode.
+- is-dual		: zynqmp qspi support for dual-parallel mode configuration
+			  value should be 1.
+- is-stacked		: zynqmp qspi support for stacked mode configuration.
+			  to enable this mode, is-dual should be 0 and is-stacked
+			  should be 1.
 
 Example:
 	qspi: spi@ff0f0000 {
diff --git a/drivers/spi/Kconfig b/drivers/spi/Kconfig
index aadaea052..1cfe2404a 100644
--- a/drivers/spi/Kconfig
+++ b/drivers/spi/Kconfig
@@ -955,6 +955,14 @@ config SPI_ZYNQ_QSPI
 	  in master mode.
 	  This controller only supports SPI memory interface.
 
+config SPI_ZYNQ_QSPI_DUAL_STACKED
+	bool "Xilinx Zynq QSPI Dual stacked configuration"
+	depends on SPI_ZYNQ_QSPI
+	help
+	  This selects the Xilinx ZYNQ Quad SPI controller in dual stacked mode.
+	  Enable this option if your hw design is using dual stacked
+	  configuration.
+
 config SPI_ZYNQMP_GQSPI
 	tristate "Xilinx ZynqMP GQSPI controller"
 	depends on (SPI_MASTER && HAS_DMA) || COMPILE_TEST
diff --git a/drivers/spi/spi-cadence-quadspi.c b/drivers/spi/spi-cadence-quadspi.c
index 2e1255bf1..3a7f87bb1 100644
--- a/drivers/spi/spi-cadence-quadspi.c
+++ b/drivers/spi/spi-cadence-quadspi.c
@@ -13,6 +13,7 @@
 #include <linux/dmaengine.h>
 #include <linux/err.h>
 #include <linux/errno.h>
+#include <linux/firmware/xlnx-zynqmp.h>
 #include <linux/interrupt.h>
 #include <linux/io.h>
 #include <linux/iopoll.h>
@@ -20,6 +21,7 @@
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/of_device.h>
+#include <linux/of_gpio.h>
 #include <linux/of.h>
 #include <linux/platform_device.h>
 #include <linux/pm_runtime.h>
@@ -28,6 +30,7 @@
 #include <linux/spi/spi.h>
 #include <linux/spi/spi-mem.h>
 #include <linux/timer.h>
+#include <linux/workqueue.h>
 
 #define CQSPI_NAME			"cadence-qspi"
 #define CQSPI_MAX_CHIPSELECT		16
@@ -35,6 +38,8 @@
 /* Quirks */
 #define CQSPI_NEEDS_WR_DELAY		BIT(0)
 #define CQSPI_DISABLE_DAC_MODE		BIT(1)
+#define CQSPI_HAS_DMA			BIT(2)
+#define CQSPI_SUPPORT_RESET		BIT(3)
 
 /* Capabilities */
 #define CQSPI_SUPPORTS_OCTAL		BIT(0)
@@ -80,6 +85,24 @@ struct cqspi_st {
 	u32			wr_delay;
 	bool			use_direct_mode;
 	struct cqspi_flash_pdata f_pdata[CQSPI_MAX_CHIPSELECT];
+	bool			read_dma;
+	void			*rxbuf;
+	int			bytes_to_rx;
+	int			bytes_to_dma;
+	loff_t			addr;
+	dma_addr_t		dma_addr;
+	u8			edge_mode;
+	bool			extra_dummy;
+	u8			access_mode;
+	bool			unalined_byte_cnt;
+	u8			dll_mode;
+	u32			pm_dev_id;
+	struct completion	tuning_complete;
+	struct completion	request_complete;
+	int (*indirect_read_dma)(struct cqspi_flash_pdata *f_pdata,
+				 u_char *rxbuf, loff_t from_addr, size_t n_rx);
+	int (*flash_reset)(struct cqspi_st *cqspi, u8 reset_type);
+	int (*access_mode_switch)(struct cqspi_flash_pdata *f_pdata);
 };
 
 struct cqspi_driver_platdata {
@@ -90,6 +113,8 @@ struct cqspi_driver_platdata {
 /* Operation timeout value */
 #define CQSPI_TIMEOUT_MS			500
 #define CQSPI_READ_TIMEOUT_MS			10
+#define CQSPI_TUNING_TIMEOUT_MS			5000
+#define CQSPI_TUNING_PERIODICITY_MS		300000
 
 /* Instruction type */
 #define CQSPI_INST_TYPE_SINGLE			0
@@ -106,11 +131,16 @@ struct cqspi_driver_platdata {
 /* Register map */
 #define CQSPI_REG_CONFIG			0x00
 #define CQSPI_REG_CONFIG_ENABLE_MASK		BIT(0)
+#define CQSPI_REG_CONFIG_PHY_ENABLE_MASK	BIT(3)
 #define CQSPI_REG_CONFIG_ENB_DIR_ACC_CTRL	BIT(7)
 #define CQSPI_REG_CONFIG_DECODE_MASK		BIT(9)
 #define CQSPI_REG_CONFIG_CHIPSELECT_LSB		10
 #define CQSPI_REG_CONFIG_DMA_MASK		BIT(15)
+#define CQSPI_REG_CONFIG_AHB_ADDR_REMAP_MASK	BIT(16)
+#define CQSPI_REG_CONFIG_DTR_PROT_EN_MASK	BIT(24)
+#define CQSPI_REG_CONFIG_DUAL_BYTE_OP		BIT(30)
 #define CQSPI_REG_CONFIG_BAUD_LSB		19
+#define CQSPI_REG_CONFIG_DUAL_OP_LSB		30
 #define CQSPI_REG_CONFIG_IDLE_LSB		31
 #define CQSPI_REG_CONFIG_CHIPSELECT_MASK	0xF
 #define CQSPI_REG_CONFIG_BAUD_MASK		0xF
@@ -129,6 +159,7 @@ struct cqspi_driver_platdata {
 
 #define CQSPI_REG_WR_INSTR			0x08
 #define CQSPI_REG_WR_INSTR_OPCODE_LSB		0
+#define CQSPI_REG_WR_INSTR_OPCODE_MASK		0xFF
 #define CQSPI_REG_WR_INSTR_TYPE_ADDR_LSB	12
 #define CQSPI_REG_WR_INSTR_TYPE_DATA_LSB	16
 
@@ -146,6 +177,7 @@ struct cqspi_driver_platdata {
 #define CQSPI_REG_READCAPTURE_BYPASS_LSB	0
 #define CQSPI_REG_READCAPTURE_DELAY_LSB		1
 #define CQSPI_REG_READCAPTURE_DELAY_MASK	0xF
+#define CQSPI_REG_READCAPTURE_DQS_ENABLE	BIT(8)
 
 #define CQSPI_REG_SIZE				0x14
 #define CQSPI_REG_SIZE_ADDRESS_LSB		0
@@ -163,6 +195,7 @@ struct cqspi_driver_platdata {
 #define CQSPI_REG_DMA_BURST_LSB			8
 #define CQSPI_REG_DMA_SINGLE_MASK		0xFF
 #define CQSPI_REG_DMA_BURST_MASK		0xFF
+#define CQSPI_REG_DMA_VAL			0x602
 
 #define CQSPI_REG_REMAP				0x24
 #define CQSPI_REG_MODE_BIT			0x28
@@ -173,8 +206,13 @@ struct cqspi_driver_platdata {
 #define CQSPI_REG_SDRAMLEVEL_RD_MASK		0xFFFF
 #define CQSPI_REG_SDRAMLEVEL_WR_MASK		0xFFFF
 
+#define CQSPI_REG_WRCOMPLETION			0x38
+#define CQSPI_REG_WRCOMPLETION_POLLCNT_MASK	0xFF0000
+#define CQSPI_REG_WRCOMPLETION_POLLCNY_LSB	16
+
 #define CQSPI_REG_IRQSTATUS			0x40
 #define CQSPI_REG_IRQMASK			0x44
+#define CQSPI_REG_ECO				0x48
 
 #define CQSPI_REG_INDIRECTRD			0x60
 #define CQSPI_REG_INDIRECTRD_START_MASK		BIT(0)
@@ -198,6 +236,8 @@ struct cqspi_driver_platdata {
 #define CQSPI_REG_CMDCTRL_WR_BYTES_MASK		0x7
 #define CQSPI_REG_CMDCTRL_ADD_BYTES_MASK	0x3
 #define CQSPI_REG_CMDCTRL_RD_BYTES_MASK		0x7
+#define CQSPI_REG_CMDCTRL_DUMMY_BYTES_LSB	7
+#define CQSPI_REG_CMDCTRL_DUMMY_BYTES_MASK      0x1F
 
 #define CQSPI_REG_INDIRECTWR			0x70
 #define CQSPI_REG_INDIRECTWR_START_MASK		BIT(0)
@@ -208,12 +248,52 @@ struct cqspi_driver_platdata {
 #define CQSPI_REG_INDIRECTWRSTARTADDR		0x78
 #define CQSPI_REG_INDIRECTWRBYTES		0x7C
 
+#define CQSPI_REG_INDTRIG_ADDRRANGE		0x80
+#define CQSPI_REG_INDTRIG_ADDRRANGE_WIDTH	0x6
+
 #define CQSPI_REG_CMDADDRESS			0x94
 #define CQSPI_REG_CMDREADDATALOWER		0xA0
 #define CQSPI_REG_CMDREADDATAUPPER		0xA4
 #define CQSPI_REG_CMDWRITEDATALOWER		0xA8
 #define CQSPI_REG_CMDWRITEDATAUPPER		0xAC
 
+#define CQSPI_REG_PHY_CONFIG			0xB4
+#define CQSPI_REG_PHY_CONFIG_RESYNC_FLD_MASK	0x80000000
+#define CQSPI_REG_PHY_CONFIG_RESET_FLD_MASK	0x40000000
+#define CQSPI_REG_PHY_CONFIG_TX_DLL_DLY_LSB	16
+
+#define CQSPI_REG_PHY_MASTER_CTRL		0xB8
+#define CQSPI_REG_DLL_LOWER			0xBC
+#define CQSPI_REG_DLL_LOWER_LPBK_LOCK_MASK	0x8000
+#define CQSPI_REG_DLL_LOWER_DLL_LOCK_MASK	0x1
+
+#define CQSPI_REG_DLL_OBSVBLE_UPPER		0xC0
+#define CQSPI_REG_DLL_UPPER_RX_FLD_MASK		0x7F
+
+#define CQSPI_REG_EXT_OP_LOWER			0xE0
+#define CQSPI_REG_EXT_STIG_OP_MASK		0xFF
+#define CQSPI_REG_EXT_READ_OP_MASK		0xFF000000
+#define CQSPI_REG_EXT_READ_OP_SHIFT		24
+#define CQSPI_REG_EXT_WRITE_OP_MASK		0xFF0000
+#define CQSPI_REG_EXT_WRITE_OP_SHIFT		16
+#define CQSPI_REG_DMA_SRC_ADDR			0x1000
+#define CQSPI_REG_DMA_DST_ADDR			0x1800
+#define CQSPI_REG_DMA_DST_SIZE			0x1804
+#define CQSPI_REG_DMA_DST_STS			0x1808
+#define CQSPI_REG_DMA_DST_CTRL			0x180C
+#define CQSPI_REG_DMA_DST_CTRL_VAL		0xF43FFA00
+
+#define CQSPI_REG_DMA_DTS_I_STS			0x1814
+#define CQSPI_REG_DMA_DST_I_EN			0x1818
+#define CQSPI_REG_DMA_DST_I_EN_DONE		BIT(1)
+
+#define CQSPI_REG_DMA_DST_I_DIS			0x181C
+#define CQSPI_REG_DMA_DST_I_DIS_DONE		BIT(1)
+#define CQSPI_REG_DMA_DST_ALL_I_DIS_MASK	0xFE
+
+#define CQSPI_REG_DMA_DST_I_MASK		0x1820
+#define CQSPI_REG_DMA_DST_ADDR_MSB		0x1828
+
 /* Interrupt status bits */
 #define CQSPI_REG_IRQ_MODE_ERR			BIT(0)
 #define CQSPI_REG_IRQ_UNDERFLOW			BIT(1)
@@ -234,6 +314,30 @@ struct cqspi_driver_platdata {
 
 #define CQSPI_IRQ_STATUS_MASK		0x1FFFF
 
+#define CQSPI_EDGE_MODE_SDR		0
+#define CQSPI_EDGE_MODE_DDR		1
+
+#define CQSPI_DMA_MODE			0
+#define CQSPI_LINEAR_MODE		1
+
+#define READ_4B_OP			0x13
+#define CQSPI_MIO_NODE_ID_12		0x14108027
+#define RESET_OSPI			0xc10402e
+#define CQSPI_RESET_TYPE_HWPIN		0
+#define CQSPI_READ_ID			0x9F
+#define CQSPI_READ_ID_LEN		6
+#define TERA_MACRO			1000000000000ULL
+#define SILICON_VER_MASK		0xFF
+#define SILICON_VER_1			0x10
+#define CQSPI_DLL_MODE_MASTER		0
+#define CQSPI_DLL_MODE_BYPASS		1
+#define TAP_GRAN_SEL_MIN_FREQ		120000000
+#define CQSPI_TX_TAP_MASTER		0x1E
+#define CQSPI_MAX_DLL_TAPS		127
+
+#define CQSPI_CS_LOWER			0
+#define CQSPI_CS_UPPER			1
+
 static int cqspi_wait_for_bit(void __iomem *reg, const u32 mask, bool clr)
 {
 	u32 val;
@@ -258,25 +362,6 @@ static u32 cqspi_get_rd_sram_level(struct cqspi_st *cqspi)
 	return reg & CQSPI_REG_SDRAMLEVEL_RD_MASK;
 }
 
-static irqreturn_t cqspi_irq_handler(int this_irq, void *dev)
-{
-	struct cqspi_st *cqspi = dev;
-	unsigned int irq_status;
-
-	/* Read interrupt status */
-	irq_status = readl(cqspi->iobase + CQSPI_REG_IRQSTATUS);
-
-	/* Clear interrupt */
-	writel(irq_status, cqspi->iobase + CQSPI_REG_IRQSTATUS);
-
-	irq_status &= CQSPI_IRQ_MASK_RD | CQSPI_IRQ_MASK_WR;
-
-	if (irq_status)
-		complete(&cqspi->transfer_complete);
-
-	return IRQ_HANDLED;
-}
-
 static unsigned int cqspi_calc_rdreg(struct cqspi_flash_pdata *f_pdata)
 {
 	u32 rdreg = 0;
@@ -345,6 +430,89 @@ static int cqspi_exec_flash_cmd(struct cqspi_st *cqspi, unsigned int reg)
 	return cqspi_wait_idle(cqspi);
 }
 
+static void process_dma_irq(struct cqspi_st *cqspi)
+{
+	struct platform_device *pdev = cqspi->pdev;
+	struct device *dev = &pdev->dev;
+	unsigned int rem;
+	unsigned int reg;
+	unsigned int data;
+	u8 addr_bytes;
+	u8 opcode;
+	u8 dummy_cycles;
+
+	/* Disable DMA interrupt */
+	writel(CQSPI_REG_DMA_DST_I_DIS_DONE,
+	       cqspi->iobase + CQSPI_REG_DMA_DST_I_DIS);
+
+	/* Clear indirect completion status */
+	writel(CQSPI_REG_INDIRECTRD_DONE_MASK,
+	       cqspi->iobase + CQSPI_REG_INDIRECTRD);
+	dma_unmap_single(dev, cqspi->dma_addr, cqspi->bytes_to_dma,
+			 DMA_FROM_DEVICE);
+	rem = cqspi->bytes_to_rx - cqspi->bytes_to_dma;
+
+	/* Read unaligned data in STIG */
+	if (rem) {
+		cqspi->rxbuf += cqspi->bytes_to_dma;
+		writel(cqspi->addr + cqspi->bytes_to_dma,
+		       cqspi->iobase + CQSPI_REG_CMDADDRESS);
+		opcode = (u8)readl(cqspi->iobase + CQSPI_REG_RD_INSTR);
+		addr_bytes = readl(cqspi->iobase + CQSPI_REG_SIZE) &
+					CQSPI_REG_SIZE_ADDRESS_MASK;
+		reg = opcode << CQSPI_REG_CMDCTRL_OPCODE_LSB;
+		reg |= (0x1 << CQSPI_REG_CMDCTRL_RD_EN_LSB);
+		reg |= (0x1 << CQSPI_REG_CMDCTRL_ADDR_EN_LSB);
+		reg |= (addr_bytes & CQSPI_REG_CMDCTRL_ADD_BYTES_MASK) <<
+			CQSPI_REG_CMDCTRL_ADD_BYTES_LSB;
+		dummy_cycles = (readl(cqspi->iobase + CQSPI_REG_RD_INSTR) >>
+				CQSPI_REG_RD_INSTR_DUMMY_LSB) &
+				CQSPI_REG_RD_INSTR_DUMMY_MASK;
+		reg |= (dummy_cycles & CQSPI_REG_CMDCTRL_DUMMY_BYTES_MASK) <<
+			CQSPI_REG_CMDCTRL_DUMMY_BYTES_LSB;
+		cqspi->unalined_byte_cnt = false;
+		if (cqspi->edge_mode == CQSPI_EDGE_MODE_DDR &&
+		    ((rem % 2) != 0)) {
+			cqspi->unalined_byte_cnt = true;
+		}
+
+		/* 0 means 1 byte. */
+		reg |= (((rem - 1 + cqspi->unalined_byte_cnt) &
+			CQSPI_REG_CMDCTRL_RD_BYTES_MASK) <<
+			CQSPI_REG_CMDCTRL_RD_BYTES_LSB);
+		cqspi_exec_flash_cmd(cqspi, reg);
+		data = readl(cqspi->iobase + CQSPI_REG_CMDREADDATALOWER);
+
+		/* Put the read value into rx_buf */
+		memcpy(cqspi->rxbuf, &data, rem);
+	}
+}
+
+static irqreturn_t cqspi_irq_handler(int this_irq, void *dev)
+{
+	struct cqspi_st *cqspi = dev;
+	unsigned int irq_status;
+	unsigned int dma_status;
+
+	/* Read interrupt status */
+	irq_status = readl(cqspi->iobase + CQSPI_REG_IRQSTATUS);
+	irq_status &= CQSPI_IRQ_MASK_RD | CQSPI_IRQ_MASK_WR;
+
+	/* Clear interrupt */
+	if (irq_status)
+		writel(irq_status, cqspi->iobase + CQSPI_REG_IRQSTATUS);
+
+	dma_status = readl(cqspi->iobase + CQSPI_REG_DMA_DTS_I_STS);
+	dma_status &= CQSPI_REG_DMA_DST_I_EN_DONE;
+	if (dma_status)
+		writel(dma_status, cqspi->iobase + CQSPI_REG_DMA_DTS_I_STS);
+
+	if (irq_status || dma_status)
+		complete(&cqspi->transfer_complete);
+
+	return IRQ_HANDLED;
+}
+
 static int cqspi_command_read(struct cqspi_flash_pdata *f_pdata,
 			      const struct spi_mem_op *op)
 {
@@ -357,6 +525,8 @@ static int cqspi_command_read(struct cqspi_flash_pdata *f_pdata,
 	unsigned int reg;
 	size_t read_len;
 	int status;
+	u8 dummy_clk;
+	u8 is_dual_op;
 
 	if (!n_rx || n_rx > CQSPI_STIG_DATA_LEN_MAX || !rxbuf) {
 		dev_err(&cqspi->pdev->dev,
@@ -365,7 +535,26 @@ static int cqspi_command_read(struct cqspi_flash_pdata *f_pdata,
 		return -EINVAL;
 	}
 
+	if (cqspi->edge_mode == CQSPI_EDGE_MODE_DDR) {
+		f_pdata->inst_width = CQSPI_INST_TYPE_OCTAL;
+		if (op->addr.nbytes)
+			f_pdata->addr_width = CQSPI_INST_TYPE_OCTAL;
+		if (op->data.nbytes)
+			f_pdata->data_width = CQSPI_INST_TYPE_OCTAL;
+	}
+
+	if (cqspi->edge_mode == CQSPI_EDGE_MODE_DDR)
+		n_rx = ((n_rx % 2) != 0) ? (n_rx + 1) : n_rx;
+
 	reg = opcode << CQSPI_REG_CMDCTRL_OPCODE_LSB;
+	if (op->addr.nbytes) {
+		reg |= (0x1 << CQSPI_REG_CMDCTRL_ADDR_EN_LSB);
+		reg |= ((op->addr.nbytes - 1) &
+			CQSPI_REG_CMDCTRL_ADD_BYTES_MASK) <<
+			CQSPI_REG_CMDCTRL_ADD_BYTES_LSB;
+
+		writel(op->addr.val, reg_base + CQSPI_REG_CMDADDRESS);
+	}
 
 	rdreg = cqspi_calc_rdreg(f_pdata);
 	writel(rdreg, reg_base + CQSPI_REG_RD_INSTR);
@@ -375,6 +564,21 @@ static int cqspi_command_read(struct cqspi_flash_pdata *f_pdata,
 	/* 0 means 1 byte. */
 	reg |= (((n_rx - 1) & CQSPI_REG_CMDCTRL_RD_BYTES_MASK)
 		<< CQSPI_REG_CMDCTRL_RD_BYTES_LSB);
+
+	dummy_clk = (op->dummy.nbytes * 8) / op->dummy.buswidth;
+	if (cqspi->edge_mode == CQSPI_EDGE_MODE_DDR && !dummy_clk)
+		dummy_clk = 8;
+
+	if (dummy_clk > CQSPI_DUMMY_CLKS_MAX)
+		dummy_clk = CQSPI_DUMMY_CLKS_MAX;
+
+	if (cqspi->extra_dummy)
+		dummy_clk++;
+
+	if (dummy_clk)
+		reg |= ((dummy_clk & CQSPI_REG_CMDCTRL_DUMMY_BYTES_MASK)
+			<< CQSPI_REG_CMDCTRL_DUMMY_BYTES_LSB);
+
 	status = cqspi_exec_flash_cmd(cqspi, reg);
 	if (status)
 		return status;
@@ -393,6 +597,15 @@ static int cqspi_command_read(struct cqspi_flash_pdata *f_pdata,
 		memcpy(rxbuf, &reg, read_len);
 	}
 
+	reg = readl(cqspi->iobase + CQSPI_REG_CONFIG);
+	is_dual_op = (reg & CQSPI_REG_CONFIG_DUAL_BYTE_OP) >>
+			CQSPI_REG_CONFIG_DUAL_OP_LSB;
+
+	if ((opcode == 0x70 && rxbuf[0] == 0x81) ||
+	    (opcode == 0x5 && rxbuf[0] == 0 && is_dual_op) ||
+	    (opcode != 0x5 && opcode != 0x70 && opcode != CQSPI_READ_ID))
+		complete(&cqspi->request_complete);
+
 	return 0;
 }
 
@@ -407,6 +620,7 @@ static int cqspi_command_write(struct cqspi_flash_pdata *f_pdata,
 	unsigned int reg;
 	unsigned int data;
 	size_t write_len;
+	int ret;
 
 	if (n_tx > CQSPI_STIG_DATA_LEN_MAX || (n_tx && !txbuf)) {
 		dev_err(&cqspi->pdev->dev,
@@ -415,6 +629,20 @@ static int cqspi_command_write(struct cqspi_flash_pdata *f_pdata,
 		return -EINVAL;
 	}
 
+	if (cqspi->edge_mode == CQSPI_EDGE_MODE_DDR) {
+		f_pdata->inst_width = CQSPI_INST_TYPE_OCTAL;
+		if (op->addr.nbytes)
+			f_pdata->addr_width = CQSPI_INST_TYPE_OCTAL;
+		if (op->data.nbytes)
+			f_pdata->data_width = CQSPI_INST_TYPE_OCTAL;
+	}
+
+	reg = f_pdata->data_width << CQSPI_REG_WR_INSTR_TYPE_DATA_LSB;
+	reg |= f_pdata->addr_width << CQSPI_REG_WR_INSTR_TYPE_ADDR_LSB;
+	writel(reg, reg_base + CQSPI_REG_WR_INSTR);
+	reg = cqspi_calc_rdreg(f_pdata);
+	writel(reg, reg_base + CQSPI_REG_RD_INSTR);
+
 	reg = opcode << CQSPI_REG_CMDCTRL_OPCODE_LSB;
 
 	if (op->addr.nbytes) {
@@ -444,7 +672,11 @@ static int cqspi_command_write(struct cqspi_flash_pdata *f_pdata,
 		}
 	}
 
-	return cqspi_exec_flash_cmd(cqspi, reg);
+	ret = cqspi_exec_flash_cmd(cqspi, reg);
+	if (!ret && opcode != 0x6 && !(op->addr.nbytes && !op->data.nbytes))
+		complete(&cqspi->request_complete);
+
+	return ret;
 }
 
 static int cqspi_read_setup(struct cqspi_flash_pdata *f_pdata,
@@ -459,9 +691,12 @@ static int cqspi_read_setup(struct cqspi_flash_pdata *f_pdata,
 	reg |= cqspi_calc_rdreg(f_pdata);
 
 	/* Setup dummy clock cycles */
-	dummy_clk = op->dummy.nbytes * 8;
+	dummy_clk = (op->dummy.nbytes * 8) / op->dummy.buswidth;
 	if (dummy_clk > CQSPI_DUMMY_CLKS_MAX)
-		return -EOPNOTSUPP;
+		dummy_clk = CQSPI_DUMMY_CLKS_MAX;
+
+	if (cqspi->extra_dummy)
+		dummy_clk++;
 
 	if (dummy_clk)
 		reg |= (dummy_clk & CQSPI_REG_RD_INSTR_DUMMY_MASK)
@@ -489,15 +724,39 @@ static int cqspi_indirect_read_execute(struct cqspi_flash_pdata *f_pdata,
 	unsigned int mod_bytes = n_rx % 4;
 	unsigned int bytes_to_read = 0;
 	u8 *rxbuf_end = rxbuf + n_rx;
+	u8 *rxbuf_start = rxbuf;
 	int ret = 0;
+	u8 extra_bytes = 0;
+	u32 reg;
+	u32 req_bytes;
+	u32 threshold_val;
+
+	reg = readl(cqspi->iobase + CQSPI_REG_CONFIG);
+	reg &= ~CQSPI_REG_CONFIG_DMA_MASK;
+	writel(reg, cqspi->iobase + CQSPI_REG_CONFIG);
+
+	if (cqspi->access_mode_switch && cqspi->access_mode == CQSPI_DMA_MODE)
+		cqspi->access_mode_switch(f_pdata);
 
 	writel(from_addr, reg_base + CQSPI_REG_INDIRECTRDSTARTADDR);
-	writel(remaining, reg_base + CQSPI_REG_INDIRECTRDBYTES);
+	if (cqspi->edge_mode == CQSPI_EDGE_MODE_DDR &&
+	    (from_addr % 2) != 0) {
+		mod_bytes += 1;
+		if (!cqspi->unalined_byte_cnt)
+			extra_bytes = 2;
+	}
+
+	if (cqspi->edge_mode == CQSPI_EDGE_MODE_DDR && (from_addr % 2) != 0)
+		writel(from_addr - 1, reg_base + CQSPI_REG_INDIRECTRDSTARTADDR);
+
+	req_bytes = remaining + cqspi->unalined_byte_cnt + extra_bytes;
+	writel(req_bytes, reg_base + CQSPI_REG_INDIRECTRDBYTES);
 
 	/* Clear all interrupts. */
 	writel(CQSPI_IRQ_STATUS_MASK, reg_base + CQSPI_REG_IRQSTATUS);
 
 	writel(CQSPI_IRQ_MASK_RD, reg_base + CQSPI_REG_IRQMASK);
+	threshold_val = readl(reg_base + CQSPI_REG_INDIRECTRDWATERMARK);
 
 	reinit_completion(&cqspi->transfer_complete);
 	writel(CQSPI_REG_INDIRECTRD_START_MASK,
@@ -508,7 +767,10 @@ static int cqspi_indirect_read_execute(struct cqspi_flash_pdata *f_pdata,
 						 msecs_to_jiffies(CQSPI_READ_TIMEOUT_MS)))
 			ret = -ETIMEDOUT;
 
-		bytes_to_read = cqspi_get_rd_sram_level(cqspi);
+		if (req_bytes > (threshold_val + cqspi->fifo_width))
+			bytes_to_read = threshold_val + cqspi->fifo_width;
+		else
+			bytes_to_read = req_bytes;
 
 		if (ret && bytes_to_read == 0) {
 			dev_err(dev, "Indirect read timeout, no bytes\n");
@@ -517,26 +779,49 @@ static int cqspi_indirect_read_execute(struct cqspi_flash_pdata *f_pdata,
 
 		while (bytes_to_read != 0) {
 			unsigned int word_remain = round_down(remaining, 4);
+			unsigned int bytes_read = 0;
 
-			bytes_to_read *= cqspi->fifo_width;
 			bytes_to_read = bytes_to_read > remaining ?
 					remaining : bytes_to_read;
 			bytes_to_read = round_down(bytes_to_read, 4);
 			/* Read 4 byte word chunks then single bytes */
 			if (bytes_to_read) {
-				ioread32_rep(ahb_base, rxbuf,
-					     (bytes_to_read / 4));
+				u8 offset = 0;
+
+				if (cqspi->edge_mode == CQSPI_EDGE_MODE_DDR &&
+				    ((from_addr % 2) != 0) && rxbuf ==
+				    rxbuf_start) {
+					unsigned int temp = ioread32(ahb_base);
+
+					temp >>= 8;
+					memcpy(rxbuf, &temp, 3);
+					bytes_to_read -= 3;
+					offset = 3;
+					bytes_read += 3;
+				}
+				if (bytes_to_read >= 4) {
+					ioread32_rep(ahb_base, rxbuf + offset,
+						     (bytes_to_read / 4));
+					bytes_read += (bytes_to_read / 4) * 4;
+				}
 			} else if (!word_remain && mod_bytes) {
 				unsigned int temp = ioread32(ahb_base);
-
-				bytes_to_read = mod_bytes;
-				memcpy(rxbuf, &temp, min((unsigned int)
-							 (rxbuf_end - rxbuf),
-							 bytes_to_read));
+				if (cqspi->edge_mode == CQSPI_EDGE_MODE_DDR &&
+				    ((from_addr % 2) != 0) && rxbuf ==
+				    rxbuf_start)
+					temp >>= 8;
+
+				bytes_to_read = min(remaining, mod_bytes);
+				bytes_read = min((unsigned int)
+						    (rxbuf_end - rxbuf),
+						     bytes_to_read);
+				memcpy(rxbuf, &temp, bytes_read);
 			}
-			rxbuf += bytes_to_read;
-			remaining -= bytes_to_read;
+			rxbuf += bytes_read;
+			remaining -= bytes_read;
+			req_bytes -= bytes_read;
 			bytes_to_read = cqspi_get_rd_sram_level(cqspi);
+			bytes_to_read *= cqspi->fifo_width;
 		}
 
 		if (remaining > 0)
@@ -556,6 +841,7 @@ static int cqspi_indirect_read_execute(struct cqspi_flash_pdata *f_pdata,
 
 	/* Clear indirect completion status */
 	writel(CQSPI_REG_INDIRECTRD_DONE_MASK, reg_base + CQSPI_REG_INDIRECTRD);
+	complete(&cqspi->request_complete);
 
 	return 0;
 
@@ -578,6 +864,8 @@ static int cqspi_write_setup(struct cqspi_flash_pdata *f_pdata,
 
 	/* Set opcode. */
 	reg = op->cmd.opcode << CQSPI_REG_WR_INSTR_OPCODE_LSB;
+	reg |= f_pdata->data_width << CQSPI_REG_WR_INSTR_TYPE_DATA_LSB;
+	reg |= f_pdata->addr_width << CQSPI_REG_WR_INSTR_TYPE_ADDR_LSB;
 	writel(reg, reg_base + CQSPI_REG_WR_INSTR);
 	reg = cqspi_calc_rdreg(f_pdata);
 	writel(reg, reg_base + CQSPI_REG_RD_INSTR);
@@ -599,9 +887,18 @@ static int cqspi_indirect_write_execute(struct cqspi_flash_pdata *f_pdata,
 	unsigned int remaining = n_tx;
 	unsigned int write_bytes;
 	int ret;
+	u32 reg;
+
+	reg = readl(cqspi->iobase + CQSPI_REG_CONFIG);
+	reg &= ~CQSPI_REG_CONFIG_DMA_MASK;
+	writel(reg, cqspi->iobase + CQSPI_REG_CONFIG);
+
+	if (cqspi->access_mode_switch && cqspi->access_mode == CQSPI_DMA_MODE)
+		cqspi->access_mode_switch(f_pdata);
 
 	writel(to_addr, reg_base + CQSPI_REG_INDIRECTWRSTARTADDR);
-	writel(remaining, reg_base + CQSPI_REG_INDIRECTWRBYTES);
+	writel(remaining + cqspi->unalined_byte_cnt,
+	       reg_base + CQSPI_REG_INDIRECTWRBYTES);
 
 	/* Clear all interrupts. */
 	writel(CQSPI_IRQ_STATUS_MASK, reg_base + CQSPI_REG_IRQSTATUS);
@@ -842,7 +1139,53 @@ static int cqspi_set_protocol(struct cqspi_flash_pdata *f_pdata,
 	f_pdata->addr_width = CQSPI_INST_TYPE_SINGLE;
 	f_pdata->data_width = CQSPI_INST_TYPE_SINGLE;
 
-	if (op->data.dir == SPI_MEM_DATA_IN) {
+	if (f_pdata->cqspi->edge_mode == CQSPI_EDGE_MODE_DDR) {
+		f_pdata->inst_width = CQSPI_INST_TYPE_OCTAL;
+		if (op->addr.nbytes)
+			f_pdata->addr_width = CQSPI_INST_TYPE_OCTAL;
+		if (op->data.nbytes)
+			f_pdata->data_width = CQSPI_INST_TYPE_OCTAL;
+
+		return 0;
+	}
+
+	switch (op->cmd.buswidth) {
+	case 1:
+		f_pdata->inst_width = CQSPI_INST_TYPE_SINGLE;
+		break;
+	case 2:
+		f_pdata->inst_width = CQSPI_INST_TYPE_DUAL;
+		break;
+	case 4:
+		f_pdata->inst_width = CQSPI_INST_TYPE_QUAD;
+		break;
+	case 8:
+		f_pdata->inst_width = CQSPI_INST_TYPE_OCTAL;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	if (op->addr.nbytes) {
+		switch (op->addr.buswidth) {
+		case 1:
+			f_pdata->addr_width = CQSPI_INST_TYPE_SINGLE;
+			break;
+		case 2:
+			f_pdata->addr_width = CQSPI_INST_TYPE_DUAL;
+			break;
+		case 4:
+			f_pdata->addr_width = CQSPI_INST_TYPE_QUAD;
+			break;
+		case 8:
+			f_pdata->addr_width = CQSPI_INST_TYPE_OCTAL;
+			break;
+		default:
+			return -EINVAL;
+		}
+	}
+
+	if (op->data.nbytes) {
 		switch (op->data.buswidth) {
 		case 1:
 			f_pdata->data_width = CQSPI_INST_TYPE_SINGLE;
@@ -881,6 +1224,12 @@ static ssize_t cqspi_write(struct cqspi_flash_pdata *f_pdata,
 	if (ret)
 		return ret;
 
+	cqspi->unalined_byte_cnt = false;
+	if (cqspi->edge_mode == CQSPI_EDGE_MODE_DDR &&
+	    ((len % 2) != 0)) {
+		cqspi->unalined_byte_cnt = true;
+	}
+
 	if (cqspi->use_direct_mode && ((to + len) <= cqspi->ahb_size)) {
 		memcpy_toio(cqspi->ahb_base + to, buf, len);
 		return cqspi_wait_idle(cqspi);
@@ -911,6 +1260,7 @@ static int cqspi_direct_read_execute(struct cqspi_flash_pdata *f_pdata,
 
 	if (!cqspi->rx_chan || !virt_addr_valid(buf)) {
 		memcpy_fromio(buf, cqspi->ahb_base + from, len);
+		complete(&cqspi->request_complete);
 		return 0;
 	}
 
@@ -948,6 +1298,7 @@ static int cqspi_direct_read_execute(struct cqspi_flash_pdata *f_pdata,
 		ret = -ETIMEDOUT;
 		goto err_unmap;
 	}
+	complete(&cqspi->request_complete);
 
 err_unmap:
 	dma_unmap_single(ddev, dma_dst, len, DMA_FROM_DEVICE);
@@ -962,6 +1313,7 @@ static ssize_t cqspi_read(struct cqspi_flash_pdata *f_pdata,
 	loff_t from = op->addr.val;
 	size_t len = op->data.nbytes;
 	u_char *buf = op->data.buf.in;
+	u64 dma_align = (u64)(uintptr_t)buf;
 	int ret;
 
 	ret = cqspi_set_protocol(f_pdata, op);
@@ -972,40 +1324,375 @@ static ssize_t cqspi_read(struct cqspi_flash_pdata *f_pdata,
 	if (ret)
 		return ret;
 
+	cqspi->unalined_byte_cnt = false;
+	if (cqspi->edge_mode == CQSPI_EDGE_MODE_DDR) {
+		if ((len % 2) != 0)
+			cqspi->unalined_byte_cnt = true;
+	}
+
 	if (cqspi->use_direct_mode && ((from + len) <= cqspi->ahb_size))
 		return cqspi_direct_read_execute(f_pdata, buf, from, len);
 
+	if (cqspi->read_dma && virt_addr_valid(buf) &&
+	    cqspi->indirect_read_dma && ((dma_align & 0x3) == 0) &&
+	    !is_vmalloc_addr(buf))
+		return cqspi->indirect_read_dma(f_pdata, buf, from, len);
+
 	return cqspi_indirect_read_execute(f_pdata, buf, from, len);
 }
 
+static int cqspi_setdlldelay(struct spi_mem *mem)
+{
+	struct cqspi_st *cqspi = spi_master_get_devdata(mem->spi->master);
+	struct platform_device *pdev = cqspi->pdev;
+	struct cqspi_flash_pdata *f_pdata;
+	int i;
+	u8 j;
+	int ret;
+	u8 id[CQSPI_READ_ID_LEN];
+	bool rxtapfound = false;
+	u8 min_rxtap = 0;
+	u8 max_rxtap = 0;
+	u8 avg_rxtap;
+	bool id_matched;
+	u32 txtap = 0;
+	u8 max_tap;
+	s8 max_windowsize = -1;
+	u8 windowsize;
+	u8 dummy_incr;
+	u8 dummy_flag = 0;
+	u32 reg;
+	u8 count;
+	u64 tera_macro = TERA_MACRO;
+	u8 max_index = 0, min_index = 0;
+	struct spi_mem_op op =
+			SPI_MEM_OP(SPI_MEM_OP_CMD(CQSPI_READ_ID, 8),
+				   SPI_MEM_OP_NO_ADDR,
+				   SPI_MEM_OP_DUMMY(8, 8),
+				   SPI_MEM_OP_DATA_IN(CQSPI_READ_ID_LEN, id, 8));
+
+	ret = cqspi_wait_idle(cqspi);
+	if (ret)
+		return ret;
+
+	f_pdata = &cqspi->f_pdata[mem->spi->chip_select];
+	max_tap = (do_div(tera_macro, cqspi->master_ref_clk_hz) / 160);
+	if (cqspi->dll_mode == CQSPI_DLL_MODE_MASTER) {
+		/* Drive DLL reset bit to low */
+		writel(0, cqspi->iobase + CQSPI_REG_PHY_CONFIG);
+
+		/* Set initial delay value */
+		writel(0x4, cqspi->iobase + CQSPI_REG_PHY_MASTER_CTRL);
+
+		/* Set DLL reset bit */
+		writel(CQSPI_REG_PHY_CONFIG_RESET_FLD_MASK,
+		       cqspi->iobase + CQSPI_REG_PHY_CONFIG);
+
+		/* Check for loopback lock */
+		ret = cqspi_wait_for_bit(cqspi->iobase + CQSPI_REG_DLL_LOWER,
+					 CQSPI_REG_DLL_LOWER_LPBK_LOCK_MASK, 0);
+		if (ret) {
+			dev_err(&pdev->dev,
+				"Loopback lock bit error (%i)\n", ret);
+			return ret;
+		}
+
+		/* Re-synchronize slave DLLs */
+		writel(CQSPI_REG_PHY_CONFIG_RESET_FLD_MASK,
+		       cqspi->iobase + CQSPI_REG_PHY_CONFIG);
+		writel(CQSPI_REG_PHY_CONFIG_RESET_FLD_MASK |
+		       CQSPI_REG_PHY_CONFIG_RESYNC_FLD_MASK,
+		       cqspi->iobase + CQSPI_REG_PHY_CONFIG);
+
+		txtap = CQSPI_TX_TAP_MASTER <<
+			CQSPI_REG_PHY_CONFIG_TX_DLL_DLY_LSB;
+		max_tap = CQSPI_MAX_DLL_TAPS;
+	}
+
+	cqspi->extra_dummy = false;
+	for (dummy_incr = 0; dummy_incr <= 1; dummy_incr++) {
+		if (dummy_incr)
+			cqspi->extra_dummy = true;
+		for (i = 0; i <= max_tap; i++) {
+			writel((txtap | i |
+			       CQSPI_REG_PHY_CONFIG_RESET_FLD_MASK),
+			       cqspi->iobase + CQSPI_REG_PHY_CONFIG);
+			writel((CQSPI_REG_PHY_CONFIG_RESYNC_FLD_MASK | txtap |
+			       i | CQSPI_REG_PHY_CONFIG_RESET_FLD_MASK),
+			       cqspi->iobase + CQSPI_REG_PHY_CONFIG);
+			if (cqspi->dll_mode == CQSPI_DLL_MODE_MASTER) {
+				ret = cqspi_wait_for_bit(cqspi->iobase +
+							 CQSPI_REG_DLL_LOWER,
+					CQSPI_REG_DLL_LOWER_DLL_LOCK_MASK, 0);
+				if (ret)
+					return ret;
+			}
+
+			if ((mem->spi->master->flags & SPI_DUAL_BYTE_OP) &&
+			    cqspi->edge_mode == CQSPI_EDGE_MODE_DDR) {
+				reg = readl(cqspi->iobase + CQSPI_REG_EXT_OP_LOWER);
+				reg &= ~CQSPI_REG_EXT_STIG_OP_MASK;
+				reg |= (u8)~CQSPI_READ_ID;
+				writel(reg, cqspi->iobase + CQSPI_REG_EXT_OP_LOWER);
+				op.addr.nbytes = 4;
+				op.addr.buswidth = 8;
+				op.addr.val = 0;
+				op.dummy.nbytes = 4;
+			}
+
+			count = 0;
+			do {
+				count += 1;
+				ret = cqspi_set_protocol(f_pdata, &op);
+				if (!ret)
+					ret = cqspi_command_read(f_pdata, &op);
+
+				if (ret < 0) {
+					dev_err(&pdev->dev,
+						"error %d reading JEDEC ID\n", ret);
+					return ret;
+				}
+
+				id_matched = true;
+				for (j = 0; j < CQSPI_READ_ID_LEN; j++) {
+					if (mem->device_id[j] != id[j]) {
+						id_matched = false;
+						break;
+					}
+				}
+			} while (id_matched && (count <= 10));
+
+			if (id_matched && !rxtapfound) {
+				if (cqspi->dll_mode == CQSPI_DLL_MODE_MASTER) {
+					min_rxtap = readl(cqspi->iobase +
+							  CQSPI_REG_DLL_OBSVBLE_UPPER) &
+							  CQSPI_REG_DLL_UPPER_RX_FLD_MASK;
+					max_rxtap = min_rxtap;
+					max_index = i;
+					min_index = i;
+				} else {
+					min_rxtap = i;
+					max_rxtap = i;
+				}
+				rxtapfound = true;
+			}
+
+			if (id_matched && rxtapfound) {
+				if (cqspi->dll_mode == CQSPI_DLL_MODE_MASTER) {
+					max_rxtap = readl(cqspi->iobase +
+							  CQSPI_REG_DLL_OBSVBLE_UPPER) &
+							  CQSPI_REG_DLL_UPPER_RX_FLD_MASK;
+					max_index = i;
+				} else {
+					max_rxtap = i;
+				}
+			}
+			if ((!id_matched || i == max_tap) && rxtapfound) {
+				windowsize = max_rxtap - min_rxtap + 1;
+				if (windowsize > max_windowsize) {
+					dummy_flag = dummy_incr;
+					max_windowsize = windowsize;
+					if (cqspi->dll_mode ==
+					    CQSPI_DLL_MODE_MASTER)
+						avg_rxtap = (max_index +
+							     min_index);
+					else
+						avg_rxtap = (max_rxtap +
+							     min_rxtap);
+					avg_rxtap /= 2;
+				}
+
+				if (windowsize >= 3)
+					i = max_tap;
+
+				rxtapfound = false;
+			}
+		}
+		if (!dummy_incr) {
+			rxtapfound = false;
+			min_rxtap = 0;
+			max_rxtap = 0;
+		}
+	}
+	if (!dummy_flag)
+		cqspi->extra_dummy = false;
+
+	if (max_windowsize < 3)
+		return -EINVAL;
+
+	writel((txtap | avg_rxtap | CQSPI_REG_PHY_CONFIG_RESET_FLD_MASK),
+	       cqspi->iobase + CQSPI_REG_PHY_CONFIG);
+	writel((CQSPI_REG_PHY_CONFIG_RESYNC_FLD_MASK | txtap | avg_rxtap |
+	       CQSPI_REG_PHY_CONFIG_RESET_FLD_MASK),
+	       cqspi->iobase + CQSPI_REG_PHY_CONFIG);
+	if (cqspi->dll_mode == CQSPI_DLL_MODE_MASTER) {
+		ret = cqspi_wait_for_bit(cqspi->iobase + CQSPI_REG_DLL_LOWER,
+					 CQSPI_REG_DLL_LOWER_DLL_LOCK_MASK, 0);
+		if (ret)
+			return ret;
+	}
+
+	return 0;
+}
+
+static void cqspi_setup_ddrmode(struct cqspi_st *cqspi)
+{
+	u32 reg;
+
+	cqspi_controller_enable(cqspi, 0);
+
+	reg = readl(cqspi->iobase + CQSPI_REG_CONFIG);
+	reg |= (CQSPI_REG_CONFIG_PHY_ENABLE_MASK);
+	writel(reg, cqspi->iobase + CQSPI_REG_CONFIG);
+
+	/* Program POLL_CNT */
+	reg = readl(cqspi->iobase + CQSPI_REG_WRCOMPLETION);
+	reg &= ~CQSPI_REG_WRCOMPLETION_POLLCNT_MASK;
+	writel(reg, cqspi->iobase + CQSPI_REG_WRCOMPLETION);
+
+	reg |= (0x3 << CQSPI_REG_WRCOMPLETION_POLLCNY_LSB);
+	writel(reg, cqspi->iobase + CQSPI_REG_WRCOMPLETION);
+
+	reg = readl(cqspi->iobase + CQSPI_REG_CONFIG);
+	reg |= CQSPI_REG_CONFIG_DTR_PROT_EN_MASK;
+	writel(reg, cqspi->iobase + CQSPI_REG_CONFIG);
+
+	reg = readl(cqspi->iobase + CQSPI_REG_READCAPTURE);
+	reg |= CQSPI_REG_READCAPTURE_DQS_ENABLE;
+	writel(reg, cqspi->iobase + CQSPI_REG_READCAPTURE);
+
+	cqspi->edge_mode = CQSPI_EDGE_MODE_DDR;
+
+	cqspi_controller_enable(cqspi, 1);
+}
+
+static void cqspi_periodictuning(struct work_struct *work)
+{
+	struct delayed_work *d = to_delayed_work(work);
+	struct spi_mem *mem = container_of(d, struct spi_mem, complete_work);
+	struct cqspi_st *cqspi = spi_master_get_devdata(mem->spi->master);
+	int ret;
+
+	if (!cqspi->request_complete.done)
+		wait_for_completion(&cqspi->request_complete);
+
+	reinit_completion(&cqspi->tuning_complete);
+	ret = cqspi_setdlldelay(mem);
+	complete_all(&cqspi->tuning_complete);
+	if (ret) {
+		dev_err(&cqspi->pdev->dev,
+			"Setting dll delay error (%i)\n", ret);
+	} else {
+		schedule_delayed_work(&mem->complete_work,
+			msecs_to_jiffies(CQSPI_TUNING_PERIODICITY_MS));
+	}
+}
+
+static int cqspi_setup_edgemode(struct spi_mem *mem)
+{
+	struct cqspi_st *cqspi = spi_master_get_devdata(mem->spi->master);
+	int ret;
+	u32 reg;
+
+	cqspi_setup_ddrmode(cqspi);
+	if (mem->spi->master->flags & SPI_DUAL_BYTE_OP) {
+		reg = readl(cqspi->iobase + CQSPI_REG_CONFIG);
+		reg |= CQSPI_REG_CONFIG_DUAL_BYTE_OP;
+		writel(reg, cqspi->iobase + CQSPI_REG_CONFIG);
+	}
+
+	ret = cqspi_setdlldelay(mem);
+	if (ret)
+		return ret;
+
+	complete_all(&cqspi->tuning_complete);
+	complete_all(&cqspi->request_complete);
+	INIT_DELAYED_WORK(&mem->complete_work, cqspi_periodictuning);
+	schedule_delayed_work(&mem->complete_work,
+			      msecs_to_jiffies(CQSPI_TUNING_PERIODICITY_MS));
+
+	return ret;
+}
+
 static int cqspi_mem_process(struct spi_mem *mem, const struct spi_mem_op *op)
 {
 	struct cqspi_st *cqspi = spi_master_get_devdata(mem->spi->master);
 	struct cqspi_flash_pdata *f_pdata;
+	void __iomem *reg_base = cqspi->iobase;
+	u32 reg;
 
 	f_pdata = &cqspi->f_pdata[mem->spi->chip_select];
+	if (mem->spi->master->flags & SPI_MASTER_U_PAGE)
+		f_pdata->cs = CQSPI_CS_UPPER;
+	else
+		f_pdata->cs = CQSPI_CS_LOWER;
+
 	cqspi_configure(f_pdata, mem->spi->max_speed_hz);
 
+	reinit_completion(&cqspi->request_complete);
+
+	if (cqspi->edge_mode == CQSPI_EDGE_MODE_DDR &&
+	    !cqspi->tuning_complete.done) {
+		if (!wait_for_completion_timeout(&cqspi->tuning_complete,
+			msecs_to_jiffies(CQSPI_TUNING_TIMEOUT_MS))) {
+			return -ETIMEDOUT;
+		}
+	}
+
+	reg = readl(reg_base + CQSPI_REG_EXT_OP_LOWER);
+	reg &= ~(CQSPI_REG_EXT_STIG_OP_MASK | CQSPI_REG_EXT_READ_OP_MASK |
+			CQSPI_REG_EXT_WRITE_OP_MASK);
 	if (op->data.dir == SPI_MEM_DATA_IN && op->data.buf.in) {
-		if (!op->addr.nbytes)
+		if (!op->addr.nbytes) {
+			if ((mem->spi->master->flags & SPI_DUAL_BYTE_OP) &&
+			    cqspi->edge_mode == CQSPI_EDGE_MODE_DDR) {
+				reg |= (u8)~op->cmd.opcode;
+				writel(reg, reg_base + CQSPI_REG_EXT_OP_LOWER);
+			}
 			return cqspi_command_read(f_pdata, op);
+		}
+
+		if ((mem->spi->master->flags & SPI_DUAL_BYTE_OP) &&
+		    cqspi->edge_mode == CQSPI_EDGE_MODE_DDR) {
+			reg |= (u8)(~op->cmd.opcode) << CQSPI_REG_EXT_READ_OP_SHIFT;
+			writel(reg, reg_base + CQSPI_REG_EXT_OP_LOWER);
+		}
 
 		return cqspi_read(f_pdata, op);
 	}
 
-	if (!op->addr.nbytes || !op->data.buf.out)
+	if (!op->addr.nbytes || !op->data.buf.out) {
+		if ((mem->spi->master->flags & SPI_DUAL_BYTE_OP) &&
+		    cqspi->edge_mode == CQSPI_EDGE_MODE_DDR) {
+			reg |= (u8)~op->cmd.opcode;
+			writel(reg, reg_base + CQSPI_REG_EXT_OP_LOWER);
+		}
+
 		return cqspi_command_write(f_pdata, op);
+	}
+
+	if ((mem->spi->master->flags & SPI_DUAL_BYTE_OP) &&
+	    cqspi->edge_mode == CQSPI_EDGE_MODE_DDR) {
+		reg |= (u8)(~op->cmd.opcode) << CQSPI_REG_EXT_WRITE_OP_SHIFT;
+		writel(reg, cqspi->iobase + CQSPI_REG_EXT_OP_LOWER);
+	}
 
 	return cqspi_write(f_pdata, op);
 }
 
 static int cqspi_exec_mem_op(struct spi_mem *mem, const struct spi_mem_op *op)
 {
+	struct cqspi_st *cqspi = spi_master_get_devdata(mem->spi->master);
 	int ret;
 
 	ret = cqspi_mem_process(mem, op);
-	if (ret)
+	if (ret) {
+		complete(&cqspi->request_complete);
 		dev_err(&mem->spi->dev, "operation failed with %d\n", ret);
+	}
+
+	if (!ret && op->cmd.tune_clk)
+		ret = cqspi_setup_edgemode(mem);
 
 	return ret;
 }
@@ -1084,8 +1771,14 @@ static void cqspi_controller_init(struct cqspi_st *cqspi)
 	/* Configure the remap address register, no remap */
 	writel(0, cqspi->iobase + CQSPI_REG_REMAP);
 
+	/* Reset the Delay lines */
+	writel(CQSPI_REG_PHY_CONFIG_RESET_FLD_MASK,
+	       cqspi->iobase + CQSPI_REG_PHY_CONFIG);
+
 	/* Disable all interrupts. */
 	writel(0, cqspi->iobase + CQSPI_REG_IRQMASK);
+	writel(CQSPI_REG_DMA_DST_ALL_I_DIS_MASK,
+	       cqspi->iobase + CQSPI_REG_DMA_DST_I_DIS);
 
 	/* Configure the SRAM split to 1:1 . */
 	writel(cqspi->fifo_depth / 2, cqspi->iobase + CQSPI_REG_SRAMPARTITION);
@@ -1103,12 +1796,259 @@ static void cqspi_controller_init(struct cqspi_st *cqspi)
 
 	/* Enable Direct Access Controller */
 	reg = readl(cqspi->iobase + CQSPI_REG_CONFIG);
-	reg |= CQSPI_REG_CONFIG_ENB_DIR_ACC_CTRL;
+	reg &= ~CQSPI_REG_CONFIG_DTR_PROT_EN_MASK;
+	reg &= ~CQSPI_REG_CONFIG_DUAL_BYTE_OP;
+	reg &= ~CQSPI_REG_CONFIG_PHY_ENABLE_MASK;
+	if (cqspi->read_dma) {
+		reg &= ~CQSPI_REG_CONFIG_ENB_DIR_ACC_CTRL;
+		reg |= CQSPI_REG_CONFIG_DMA_MASK;
+	} else {
+		/* Enable Direct Access Controller */
+		reg |= CQSPI_REG_CONFIG_ENB_DIR_ACC_CTRL;
+	}
 	writel(reg, cqspi->iobase + CQSPI_REG_CONFIG);
 
 	cqspi_controller_enable(cqspi, 1);
 }
 
+static int cqspi_versal_mode_switch(struct cqspi_flash_pdata *f_pdata)
+{
+	struct cqspi_st *cqspi = f_pdata->cqspi;
+	u32 phy_reg, rd_instr, addr_width;
+
+	if (cqspi->access_mode == CQSPI_DMA_MODE) {
+		cqspi_wait_idle(cqspi);
+		zynqmp_pm_ospi_mux_select(cqspi->pm_dev_id,
+					  PM_OSPI_MUX_SEL_LINEAR);
+		cqspi->access_mode = CQSPI_LINEAR_MODE;
+	} else if (cqspi->access_mode == CQSPI_LINEAR_MODE) {
+		cqspi_wait_idle(cqspi);
+
+		/* Issue controller reset */
+		if (cqspi->dll_mode != CQSPI_DLL_MODE_MASTER) {
+			phy_reg = readl(cqspi->iobase + CQSPI_REG_PHY_CONFIG);
+			rd_instr = readl(cqspi->iobase + CQSPI_REG_RD_INSTR);
+			addr_width = readl(cqspi->iobase + CQSPI_REG_SIZE);
+			zynqmp_pm_reset_assert(RESET_OSPI, PM_RESET_ACTION_ASSERT);
+		}
+
+		zynqmp_pm_ospi_mux_select(cqspi->pm_dev_id,
+					  PM_OSPI_MUX_SEL_DMA);
+		cqspi->access_mode = CQSPI_DMA_MODE;
+		if (cqspi->dll_mode != CQSPI_DLL_MODE_MASTER) {
+			zynqmp_pm_reset_assert(RESET_OSPI, PM_RESET_ACTION_RELEASE);
+			cqspi_controller_init(cqspi);
+			cqspi->current_cs = -1;
+			cqspi->sclk = 0;
+			if (cqspi->edge_mode == CQSPI_EDGE_MODE_DDR) {
+				cqspi_setup_ddrmode(cqspi);
+				writel(CQSPI_REG_PHY_CONFIG_RESYNC_FLD_MASK | phy_reg,
+				       cqspi->iobase + CQSPI_REG_PHY_CONFIG);
+			}
+
+			writel(rd_instr, cqspi->iobase + CQSPI_REG_RD_INSTR);
+			writel(addr_width, cqspi->iobase + CQSPI_REG_SIZE);
+		}
+	} else {
+		return -EINVAL;
+	}
+
+	writel(CQSPI_REG_INDTRIG_ADDRRANGE_WIDTH,
+	       cqspi->iobase + CQSPI_REG_INDTRIG_ADDRRANGE);
+
+	return 0;
+}
+
+static int cqspi_versal_flash_reset(struct cqspi_st *cqspi, u8 reset_type)
+{
+	struct platform_device *pdev = cqspi->pdev;
+	int ret;
+	int gpio;
+	enum of_gpio_flags flags;
+
+	if (reset_type == CQSPI_RESET_TYPE_HWPIN) {
+		gpio = of_get_named_gpio_flags(pdev->dev.of_node,
+					       "reset-gpios", 0, &flags);
+		if (!gpio_is_valid(gpio))
+			return -EIO;
+		ret = devm_gpio_request_one(&pdev->dev, gpio, flags,
+					    "flash-reset");
+		if (ret) {
+			dev_err(&pdev->dev,
+				"failed to get reset-gpios: %d\n", ret);
+			return -EIO;
+		}
+
+		/* Request for PIN */
+		zynqmp_pm_pinctrl_request(CQSPI_MIO_NODE_ID_12);
+
+		/* Enable hysteresis in cmos receiver */
+		zynqmp_pm_pinctrl_set_config(CQSPI_MIO_NODE_ID_12,
+					     PM_PINCTRL_CONFIG_SCHMITT_CMOS,
+					     PM_PINCTRL_INPUT_TYPE_SCHMITT);
+
+		/* Set the direction as output and enable the output */
+		gpio_direction_output(gpio, 1);
+
+		/* Disable Tri-state */
+		zynqmp_pm_pinctrl_set_config(CQSPI_MIO_NODE_ID_12,
+					     PM_PINCTRL_CONFIG_TRI_STATE,
+					     PM_PINCTRL_TRI_STATE_DISABLE);
+		udelay(1);
+
+		/* Set value 0 to pin */
+		gpio_set_value(gpio, 0);
+		udelay(10);
+
+		/* Set value 1 to pin */
+		gpio_set_value(gpio, 1);
+		udelay(35);
+	} else {
+		ret = -EINVAL;
+	}
+
+	return ret;
+}
+
+static int cqspi_versal_indirect_read_dma(struct cqspi_flash_pdata *f_pdata,
+					  u_char *rxbuf, loff_t from_addr,
+					  size_t n_rx)
+{
+	struct cqspi_st *cqspi = f_pdata->cqspi;
+	struct device *dev = &cqspi->pdev->dev;
+	void __iomem *reg_base = cqspi->iobase;
+	unsigned int rx_rem;
+	int ret = 0;
+	u32 reg;
+
+	rx_rem = n_rx % 4;
+	cqspi->bytes_to_rx = n_rx;
+	cqspi->bytes_to_dma = (n_rx - rx_rem);
+	cqspi->addr = from_addr;
+	cqspi->rxbuf = rxbuf;
+
+	if (((from_addr % 2) != 0) &&
+	    cqspi->edge_mode == CQSPI_EDGE_MODE_DDR) {
+		u8 addr_bytes, opcode, dummy_cycles;
+		unsigned int data;
+
+		writel(cqspi->addr - 1, cqspi->iobase + CQSPI_REG_CMDADDRESS);
+		opcode = (u8)readl(cqspi->iobase + CQSPI_REG_RD_INSTR);
+		addr_bytes = readl(cqspi->iobase + CQSPI_REG_SIZE) &
+					CQSPI_REG_SIZE_ADDRESS_MASK;
+		reg = opcode << CQSPI_REG_CMDCTRL_OPCODE_LSB;
+		reg |= (0x1 << CQSPI_REG_CMDCTRL_RD_EN_LSB);
+		reg |= (0x1 << CQSPI_REG_CMDCTRL_ADDR_EN_LSB);
+		reg |= (addr_bytes & CQSPI_REG_CMDCTRL_ADD_BYTES_MASK) <<
+				CQSPI_REG_CMDCTRL_ADD_BYTES_LSB;
+		dummy_cycles = (readl(cqspi->iobase + CQSPI_REG_RD_INSTR) >>
+				CQSPI_REG_RD_INSTR_DUMMY_LSB) &
+				CQSPI_REG_RD_INSTR_DUMMY_MASK;
+		reg |= (dummy_cycles & CQSPI_REG_CMDCTRL_DUMMY_BYTES_MASK) <<
+			CQSPI_REG_CMDCTRL_DUMMY_BYTES_LSB;
+		reg |= ((0x1 & CQSPI_REG_CMDCTRL_RD_BYTES_MASK) <<
+			CQSPI_REG_CMDCTRL_RD_BYTES_LSB);
+		cqspi_exec_flash_cmd(cqspi, reg);
+		data = readl(cqspi->iobase + CQSPI_REG_CMDREADDATALOWER);
+		data = data >> 8;
+		memcpy(cqspi->rxbuf, &data, 1);
+		cqspi->bytes_to_rx -= 1;
+		cqspi->addr += 1;
+		cqspi->rxbuf += 1;
+		rx_rem = cqspi->bytes_to_rx % 4;
+		cqspi->bytes_to_dma = (cqspi->bytes_to_rx - rx_rem);
+	}
+
+	if (cqspi->bytes_to_rx < 4) {
+		process_dma_irq(cqspi);
+		complete(&cqspi->request_complete);
+		return 0;
+	}
+
+	reg = readl(cqspi->iobase + CQSPI_REG_CONFIG);
+	reg |= CQSPI_REG_CONFIG_DMA_MASK;
+	writel(reg, cqspi->iobase + CQSPI_REG_CONFIG);
+
+	if (cqspi->access_mode_switch &&
+	    cqspi->access_mode == CQSPI_LINEAR_MODE)
+		cqspi->access_mode_switch(f_pdata);
+
+	writel(cqspi->addr, reg_base + CQSPI_REG_INDIRECTRDSTARTADDR);
+	writel(cqspi->bytes_to_dma, reg_base + CQSPI_REG_INDIRECTRDBYTES);
+	writel(CQSPI_REG_INDTRIG_ADDRRANGE_WIDTH,
+	       reg_base + CQSPI_REG_INDTRIG_ADDRRANGE);
+
+	/* Clear all interrupts. */
+	writel(CQSPI_IRQ_STATUS_MASK, reg_base + CQSPI_REG_IRQSTATUS);
+
+	/* Enable DMA done interrupt */
+	writel(CQSPI_REG_DMA_DST_I_EN_DONE,
+	       reg_base + CQSPI_REG_DMA_DST_I_EN);
+
+	/* Default DMA periph configuration */
+	writel(CQSPI_REG_DMA_VAL, reg_base + CQSPI_REG_DMA);
+
+	cqspi->dma_addr = dma_map_single(dev, cqspi->rxbuf, cqspi->bytes_to_dma,
+					 DMA_FROM_DEVICE);
+	if (dma_mapping_error(dev, cqspi->dma_addr)) {
+		dev_err(dev, "ERR:rxdma:memory not mapped\n");
+		goto failrd;
+	}
+	/* Configure DMA Dst address */
+	writel(lower_32_bits(cqspi->dma_addr),
+	       reg_base + CQSPI_REG_DMA_DST_ADDR);
+	writel(upper_32_bits(cqspi->dma_addr),
+	       reg_base + CQSPI_REG_DMA_DST_ADDR_MSB);
+
+	/* Configure DMA Src read address */
+	writel(cqspi->trigger_address, reg_base + CQSPI_REG_DMA_SRC_ADDR);
+
+	/* Set DMA destination size */
+	writel(cqspi->bytes_to_dma, reg_base + CQSPI_REG_DMA_DST_SIZE);
+
+	/* Set DMA destination control */
+	writel(CQSPI_REG_DMA_DST_CTRL_VAL, reg_base + CQSPI_REG_DMA_DST_CTRL);
+
+	writel(CQSPI_REG_INDIRECTRD_START_MASK,
+	       reg_base + CQSPI_REG_INDIRECTRD);
+
+	reinit_completion(&cqspi->transfer_complete);
+
+	if (!wait_for_completion_timeout(&cqspi->transfer_complete,
+			msecs_to_jiffies(CQSPI_READ_TIMEOUT_MS))) {
+		ret = -ETIMEDOUT;
+		goto failrd;
+	}
+
+	/* Check indirect done status */
+	ret = cqspi_wait_for_bit(reg_base + CQSPI_REG_INDIRECTRD,
+				 CQSPI_REG_INDIRECTRD_DONE_MASK, 0);
+	if (ret) {
+		dev_err(dev,
+			"Indirect read completion error (%i)\n", ret);
+		goto failrd;
+	}
+
+	process_dma_irq(cqspi);
+	complete(&cqspi->request_complete);
+
+	return 0;
+
+failrd:
+	/* Disable DMA interrupt */
+	writel(CQSPI_REG_DMA_DST_I_DIS_DONE,
+	       reg_base + CQSPI_REG_DMA_DST_I_DIS);
+
+	dma_unmap_single(dev, cqspi->dma_addr, cqspi->bytes_to_dma,
+			 DMA_DEV_TO_MEM);
+
+	/* Cancel the indirect read */
+	writel(CQSPI_REG_INDIRECTWR_CANCEL_MASK,
+	       reg_base + CQSPI_REG_INDIRECTRD);
+
+	return ret;
+}
+
 static int cqspi_request_mmap_dma(struct cqspi_st *cqspi)
 {
 	dma_cap_mask_t mask;
@@ -1185,6 +2125,9 @@ static int cqspi_probe(struct platform_device *pdev)
 	struct resource *res;
 	int ret;
 	int irq;
+	u32 idcode;
+	u32 version;
+	u32 id[2];
 
 	master = spi_alloc_master(&pdev->dev, sizeof(*cqspi));
 	if (!master) {
@@ -1198,7 +2141,6 @@ static int cqspi_probe(struct platform_device *pdev)
 	cqspi = spi_master_get_devdata(master);
 
 	cqspi->pdev = pdev;
-	platform_set_drvdata(pdev, cqspi);
 
 	/* Obtain configuration from OF. */
 	ret = cqspi_of_get_pdata(cqspi);
@@ -1237,6 +2179,8 @@ static int cqspi_probe(struct platform_device *pdev)
 	cqspi->ahb_size = resource_size(res_ahb);
 
 	init_completion(&cqspi->transfer_complete);
+	init_completion(&cqspi->tuning_complete);
+	init_completion(&cqspi->request_complete);
 
 	/* Obtain IRQ line. */
 	irq = platform_get_irq(pdev, 0);
@@ -1280,6 +2224,7 @@ static int cqspi_probe(struct platform_device *pdev)
 	reset_control_deassert(rstc_ocp);
 
 	cqspi->master_ref_clk_hz = clk_get_rate(cqspi->clk);
+	cqspi->pm_dev_id = 0;
 	ddata  = of_device_get_match_data(dev);
 	if (ddata) {
 		if (ddata->quirks & CQSPI_NEEDS_WR_DELAY)
@@ -1289,6 +2234,43 @@ static int cqspi_probe(struct platform_device *pdev)
 			master->mode_bits |= SPI_RX_OCTAL;
 		if (!(ddata->quirks & CQSPI_DISABLE_DAC_MODE))
 			cqspi->use_direct_mode = true;
+
+		if (ddata && (ddata->quirks & CQSPI_HAS_DMA)) {
+			dma_set_mask(&pdev->dev, DMA_BIT_MASK(64));
+			cqspi->read_dma = true;
+		}
+
+		if (of_device_is_compatible(pdev->dev.of_node,
+					    "xlnx,versal-ospi-1.0") &&
+					    cqspi->read_dma) {
+			master->mode_bits |= SPI_TX_OCTAL;
+			cqspi->indirect_read_dma =
+					cqspi_versal_indirect_read_dma;
+			cqspi->flash_reset = cqspi_versal_flash_reset;
+			cqspi->access_mode_switch = cqspi_versal_mode_switch;
+			cqspi->dll_mode = CQSPI_DLL_MODE_BYPASS;
+
+			ret = zynqmp_pm_get_chipid(&idcode, &version);
+			if (ret < 0) {
+				dev_err(dev, "Cannot get chipid is %d\n", ret);
+				goto probe_clk_failed;
+			}
+			if ((version & SILICON_VER_MASK) != SILICON_VER_1) {
+				cqspi->dll_mode = CQSPI_DLL_MODE_MASTER;
+				if (cqspi->master_ref_clk_hz >= TAP_GRAN_SEL_MIN_FREQ)
+					writel(0x1, cqspi->iobase + CQSPI_REG_ECO);
+			}
+
+			ret = of_property_read_u32_array(pdev->dev.of_node,
+							 "power-domains", id,
+							 ARRAY_SIZE(id));
+			if (ret < 0) {
+				dev_err(&pdev->dev,
+					"Failed to read pm device id information\n");
+				goto probe_clk_failed;
+			}
+			cqspi->pm_dev_id = id[1];
+		}
 	}
 
 	ret = devm_request_irq(dev, irq, cqspi_irq_handler, 0,
@@ -1302,6 +2284,10 @@ static int cqspi_probe(struct platform_device *pdev)
 	cqspi_controller_init(cqspi);
 	cqspi->current_cs = -1;
 	cqspi->sclk = 0;
+	cqspi->extra_dummy = false;
+	cqspi->edge_mode = CQSPI_EDGE_MODE_SDR;
+	cqspi->access_mode = CQSPI_DMA_MODE;
+	cqspi->unalined_byte_cnt = false;
 
 	ret = cqspi_setup_flash(cqspi);
 	if (ret) {
@@ -1309,6 +2295,12 @@ static int cqspi_probe(struct platform_device *pdev)
 		goto probe_setup_failed;
 	}
 
+	if (ddata->quirks & CQSPI_SUPPORT_RESET) {
+		ret = cqspi->flash_reset(cqspi, CQSPI_RESET_TYPE_HWPIN);
+		if (ret)
+			goto probe_setup_failed;
+	}
+
 	if (cqspi->use_direct_mode) {
 		ret = cqspi_request_mmap_dma(cqspi);
 		if (ret == -EPROBE_DEFER)
@@ -1391,6 +2383,11 @@ static const struct cqspi_driver_platdata am654_ospi = {
 	.quirks = CQSPI_NEEDS_WR_DELAY,
 };
 
+static const struct cqspi_driver_platdata versal_ospi = {
+	.hwcaps_mask = CQSPI_SUPPORTS_OCTAL,
+	.quirks = CQSPI_HAS_DMA | CQSPI_DISABLE_DAC_MODE | CQSPI_SUPPORT_RESET,
+};
+
 static const struct of_device_id cqspi_dt_ids[] = {
 	{
 		.compatible = "cdns,qspi-nor",
@@ -1404,6 +2401,10 @@ static const struct of_device_id cqspi_dt_ids[] = {
 		.compatible = "ti,am654-ospi",
 		.data = &am654_ospi,
 	},
+	{
+		.compatible = "xlnx,versal-ospi-1.0",
+		.data = (void *)&versal_ospi,
+	},
 	{ /* end of table */ }
 };
 
diff --git a/drivers/spi/spi-cadence.c b/drivers/spi/spi-cadence.c
index ceb16e70d..57eff653f 100644
--- a/drivers/spi/spi-cadence.c
+++ b/drivers/spi/spi-cadence.c
@@ -69,6 +69,7 @@
 #define CDNS_SPI_BAUD_DIV_SHIFT		3 /* Baud rate divisor shift in CR */
 #define CDNS_SPI_SS_SHIFT		10 /* Slave Select field shift in CR */
 #define CDNS_SPI_SS0			0x1 /* Slave Select zero */
+#define CDNS_SPI_NOSS			0x3C /* No Slave select */
 
 /*
  * SPI Interrupt Registers bit Masks
@@ -342,7 +343,8 @@ static irqreturn_t cdns_spi_irq(int irq, void *dev_id)
 {
 	struct spi_master *master = dev_id;
 	struct cdns_spi *xspi = spi_master_get_devdata(master);
-	u32 intr_status, status;
+	u32 intr_status;
+	irqreturn_t status;
 
 	status = IRQ_NONE;
 	intr_status = cdns_spi_read(xspi, CDNS_SPI_ISR);
@@ -449,15 +451,20 @@ static int cdns_prepare_transfer_hardware(struct spi_master *master)
  * @master:	Pointer to the spi_master structure which provides
  *		information about the controller.
  *
- * This function disables the SPI master controller.
+ * This function disables the SPI master controller when no slave selected.
  *
  * Return:	0 always
  */
 static int cdns_unprepare_transfer_hardware(struct spi_master *master)
 {
 	struct cdns_spi *xspi = spi_master_get_devdata(master);
+	u32 ctrl_reg;
 
-	cdns_spi_write(xspi, CDNS_SPI_ER, CDNS_SPI_ER_DISABLE);
+	/* Disable the SPI if slave is deselected */
+	ctrl_reg = cdns_spi_read(xspi, CDNS_SPI_CR);
+	ctrl_reg = (ctrl_reg & CDNS_SPI_CR_SSCTRL) >>  CDNS_SPI_SS_SHIFT;
+	if (ctrl_reg == CDNS_SPI_NOSS)
+		cdns_spi_write(xspi, CDNS_SPI_ER, CDNS_SPI_ER_DISABLE);
 
 	return 0;
 }
@@ -475,7 +482,7 @@ static int cdns_spi_probe(struct platform_device *pdev)
 	int ret = 0, irq;
 	struct spi_master *master;
 	struct cdns_spi *xspi;
-	u32 num_cs;
+	u32 num_cs = 0;
 
 	master = spi_alloc_master(&pdev->dev, sizeof(*xspi));
 	if (!master)
@@ -650,14 +657,14 @@ static int __maybe_unused cdns_spi_resume(struct device *dev)
 }
 
 /**
- * cdns_spi_runtime_resume - Runtime resume method for the SPI driver
+ * cdns_runtime_resume - Runtime resume method for the SPI driver
  * @dev:	Address of the platform_device structure
  *
  * This function enables the clocks
  *
  * Return:	0 on success and error value on error
  */
-static int __maybe_unused cnds_runtime_resume(struct device *dev)
+static int __maybe_unused cdns_runtime_resume(struct device *dev)
 {
 	struct spi_master *master = dev_get_drvdata(dev);
 	struct cdns_spi *xspi = spi_master_get_devdata(master);
@@ -679,14 +686,14 @@ static int __maybe_unused cnds_runtime_resume(struct device *dev)
 }
 
 /**
- * cdns_spi_runtime_suspend - Runtime suspend method for the SPI driver
+ * cdns_runtime_suspend - Runtime suspend method for the SPI driver
  * @dev:	Address of the platform_device structure
  *
  * This function disables the clocks
  *
  * Return:	Always 0
  */
-static int __maybe_unused cnds_runtime_suspend(struct device *dev)
+static int __maybe_unused cdns_runtime_suspend(struct device *dev)
 {
 	struct spi_master *master = dev_get_drvdata(dev);
 	struct cdns_spi *xspi = spi_master_get_devdata(master);
@@ -698,8 +705,8 @@ static int __maybe_unused cnds_runtime_suspend(struct device *dev)
 }
 
 static const struct dev_pm_ops cdns_spi_dev_pm_ops = {
-	SET_RUNTIME_PM_OPS(cnds_runtime_suspend,
-			   cnds_runtime_resume, NULL)
+	SET_RUNTIME_PM_OPS(cdns_runtime_suspend,
+			   cdns_runtime_resume, NULL)
 	SET_SYSTEM_SLEEP_PM_OPS(cdns_spi_suspend, cdns_spi_resume)
 };
 
diff --git a/drivers/spi/spi-mem.c b/drivers/spi/spi-mem.c
index 4682f49dc..0aa2e4622 100644
--- a/drivers/spi/spi-mem.c
+++ b/drivers/spi/spi-mem.c
@@ -7,6 +7,7 @@
  */
 #include <linux/dmaengine.h>
 #include <linux/pm_runtime.h>
+#include <linux/mtd/spi-nor.h>
 #include <linux/spi/spi.h>
 #include <linux/spi/spi-mem.h>
 
@@ -14,6 +15,25 @@
 
 #define SPI_MEM_MAX_BUSWIDTH		8
 
+bool update_stripe(const struct spi_mem_op *op)
+{
+	if (op->cmd.opcode ==  SPINOR_OP_BE_4K ||
+	    op->cmd.opcode ==  SPINOR_OP_BE_32K ||
+	    op->cmd.opcode ==  SPINOR_OP_CHIP_ERASE ||
+	    op->cmd.opcode ==  SPINOR_OP_SE ||
+	    op->cmd.opcode ==  SPINOR_OP_BE_32K_4B ||
+	    op->cmd.opcode ==  SPINOR_OP_SE_4B ||
+	    op->cmd.opcode == SPINOR_OP_BE_4K_4B ||
+	    op->cmd.opcode ==  SPINOR_OP_WRSR ||
+	    op->cmd.opcode ==  SPINOR_OP_WREAR ||
+	    op->cmd.opcode ==  SPINOR_OP_BRWR ||
+	    (op->cmd.opcode ==  SPINOR_OP_WRSR2 && !op->addr.nbytes))
+		return false;
+
+	return true;
+}
+EXPORT_SYMBOL(update_stripe);
+
 /**
  * spi_controller_dma_map_mem_op_data() - DMA-map the buffer attached to a
  *					  memory operation
@@ -354,6 +374,7 @@ int spi_mem_exec_op(struct spi_mem *mem, const struct spi_mem_op *op)
 		xfers[xferpos].tx_buf = tmpbuf + op->addr.nbytes + 1;
 		xfers[xferpos].len = op->dummy.nbytes;
 		xfers[xferpos].tx_nbits = op->dummy.buswidth;
+		xfers[xferpos].dummy = op->dummy.nbytes * 8;
 		spi_message_add_tail(&xfers[xferpos], &msg);
 		xferpos++;
 		totalxferlen += op->dummy.nbytes;
@@ -368,6 +389,7 @@ int spi_mem_exec_op(struct spi_mem *mem, const struct spi_mem_op *op)
 			xfers[xferpos].tx_nbits = op->data.buswidth;
 		}
 
+		xfers[xferpos].stripe = update_stripe(op);
 		xfers[xferpos].len = op->data.nbytes;
 		spi_message_add_tail(&xfers[xferpos], &msg);
 		xferpos++;
diff --git a/drivers/spi/spi-xilinx.c b/drivers/spi/spi-xilinx.c
index 523edfdf5..8c9a28a28 100644
--- a/drivers/spi/spi-xilinx.c
+++ b/drivers/spi/spi-xilinx.c
@@ -16,10 +16,11 @@
 #include <linux/of.h>
 #include <linux/platform_device.h>
 #include <linux/spi/spi.h>
-#include <linux/spi/spi_bitbang.h>
 #include <linux/spi/xilinx_spi.h>
 #include <linux/io.h>
-
+#include <linux/delay.h>
+#include <linux/pm_runtime.h>
+#include <linux/clk.h>
 #define XILINX_SPI_MAX_CS	32
 
 #define XILINX_SPI_NAME "xilinx_spi"
@@ -76,14 +77,51 @@
 #define XIPIF_V123B_RESETR_OFFSET	0x40	/* IPIF reset register */
 #define XIPIF_V123B_RESET_MASK		0x0a	/* the value to write */
 
+/* Number of bits per word */
+#define XSPI_ONE_BITS_PER_WORD 1
+#define XSPI_TWO_BITS_PER_WORD 2
+#define XSPI_FOUR_BITS_PER_WORD 4
+
+/* Number of data lines used to receive */
+#define XSPI_RX_ONE_WIRE	1
+#define XSPI_RX_FOUR_WIRE	4
+
+/* Auto suspend timeout in milliseconds */
+#define SPI_AUTOSUSPEND_TIMEOUT		3000
+
+/* Command used for Dummy read Id */
+#define SPI_READ_ID		0x9F
+
+/**
+ * struct xilinx_spi - This definition define spi driver instance
+ * @regs:		virt. address of the control registers
+ * @irq:		IRQ number
+ * @axi_clk:		Pointer to the AXI clock
+ * @axi4_clk:		Pointer to the AXI4 clock
+ * @spi_clk:		Pointer to the SPI clock
+ * @dev:		Pointer to the device
+ * @rx_ptr:		Pointer to the RX buffer
+ * @tx_ptr:		Pointer to the TX buffer
+ * @bytes_per_word:	Number of bytes in a word
+ * @buffer_size:	Buffer size in words
+ * @cs_inactive:	Level of the CS pins when inactive
+ * @read_fn:		For reading data from SPI registers
+ * @write_fn:		For writing data to SPI registers
+ * @bytes_to_transfer:	Number of bytes left to transfer
+ * @bytes_to_receive:	Number of bytes left to receive
+ * @rx_bus_width:	Number of wires used to receive data
+ * @tx_fifo:		For writing data to fifo
+ * @rx_fifo:		For reading data from fifo
+ */
 struct xilinx_spi {
-	/* bitbang has to be first */
-	struct spi_bitbang bitbang;
-	struct completion done;
 	void __iomem	*regs;	/* virt. address of the control registers */
 
 	int		irq;
 
+	struct clk *axi_clk;
+	struct clk *axi4_clk;
+	struct clk *spi_clk;
+	struct device *dev;
 	u8 *rx_ptr;		/* pointer in the Tx buffer */
 	const u8 *tx_ptr;	/* pointer in the Rx buffer */
 	u8 bytes_per_word;
@@ -91,8 +129,69 @@ struct xilinx_spi {
 	u32 cs_inactive;	/* Level of the CS pins when inactive*/
 	unsigned int (*read_fn)(void __iomem *);
 	void (*write_fn)(u32, void __iomem *);
+	u32 bytes_to_transfer;
+	u32 bytes_to_receive;
+	u32 rx_bus_width;
+	void (*tx_fifo)(struct xilinx_spi *xqspi);
+	void (*rx_fifo)(struct xilinx_spi *xqspi);
 };
 
+/**
+ * XSPI_FIFO_READ - Generate xspi_read_rx_fifo_* functions
+ * @size: bits_per_word that are read from RX FIFO
+ * @type: C type of value argument
+ *
+ * Generates xspi_read_rx_fifo_* functions used to write
+ * data into RX FIFO for different transaction widths.
+ */
+#define XSPI_FIFO_READ(size, type)					\
+static void xspi_read_rx_fifo_##size(struct xilinx_spi *xqspi)		\
+{									\
+	int i;								\
+	int count = (xqspi->bytes_to_receive > xqspi->buffer_size) ?	\
+			xqspi->buffer_size : xqspi->bytes_to_receive;	\
+	u32 data;							\
+	for (i = 0; i < count; i += (size / 8)) {			\
+		data = readl_relaxed(xqspi->regs + XSPI_RXD_OFFSET);	\
+		if (xqspi->rx_ptr)					\
+			((type *)xqspi->rx_ptr)[i] = (type)data;	\
+	}								\
+	xqspi->bytes_to_receive -= count;				\
+	if (xqspi->rx_ptr)						\
+		xqspi->rx_ptr += count;					\
+}
+
+/**
+ * XSPI_FIFO_WRITE - Generate xspi_fill_tx_fifo_* functions
+ * @size: bits_per_word that are written into TX FIFO
+ * @type: C type of value argument
+ *
+ * Generates xspi_fill_tx_fifo_* functions used to write
+ * data into TX FIFO for different transaction widths.
+ */
+#define XSPI_FIFO_WRITE(size, type)					\
+static void xspi_fill_tx_fifo_##size(struct xilinx_spi *xqspi)		\
+{									\
+	int i;								\
+	int count = (xqspi->bytes_to_transfer > xqspi->buffer_size) ?	\
+			xqspi->buffer_size : xqspi->bytes_to_transfer;	\
+	u32 data = 0;							\
+	for (i = 0; i < count; i += (size / 8)) {			\
+		if (xqspi->tx_ptr)					\
+			data = *(type *)&xqspi->tx_ptr[i];		\
+		writel_relaxed(data, (xqspi->regs + XSPI_TXD_OFFSET));	\
+	}								\
+	xqspi->bytes_to_transfer -= count;				\
+	if (xqspi->tx_ptr)						\
+		xqspi->tx_ptr += count;					\
+}
+
+XSPI_FIFO_READ(8, u8)
+XSPI_FIFO_READ(16, u16)
+XSPI_FIFO_READ(32, u32)
+XSPI_FIFO_WRITE(8, u8)
+XSPI_FIFO_WRITE(16, u16)
+XSPI_FIFO_WRITE(32, u32)
 static void xspi_write32(u32 val, void __iomem *addr)
 {
 	iowrite32(val, addr);
@@ -113,53 +212,15 @@ static unsigned int xspi_read32_be(void __iomem *addr)
 	return ioread32be(addr);
 }
 
-static void xilinx_spi_tx(struct xilinx_spi *xspi)
-{
-	u32 data = 0;
-
-	if (!xspi->tx_ptr) {
-		xspi->write_fn(0, xspi->regs + XSPI_TXD_OFFSET);
-		return;
-	}
-
-	switch (xspi->bytes_per_word) {
-	case 1:
-		data = *(u8 *)(xspi->tx_ptr);
-		break;
-	case 2:
-		data = *(u16 *)(xspi->tx_ptr);
-		break;
-	case 4:
-		data = *(u32 *)(xspi->tx_ptr);
-		break;
-	}
-
-	xspi->write_fn(data, xspi->regs + XSPI_TXD_OFFSET);
-	xspi->tx_ptr += xspi->bytes_per_word;
-}
-
-static void xilinx_spi_rx(struct xilinx_spi *xspi)
-{
-	u32 data = xspi->read_fn(xspi->regs + XSPI_RXD_OFFSET);
-
-	if (!xspi->rx_ptr)
-		return;
-
-	switch (xspi->bytes_per_word) {
-	case 1:
-		*(u8 *)(xspi->rx_ptr) = data;
-		break;
-	case 2:
-		*(u16 *)(xspi->rx_ptr) = data;
-		break;
-	case 4:
-		*(u32 *)(xspi->rx_ptr) = data;
-		break;
-	}
-
-	xspi->rx_ptr += xspi->bytes_per_word;
-}
-
+/**
+ * xspi_init_hw - Initialize the hardware
+ * @xspi:	Pointer to the zynqmp_qspi structure
+ *
+ * This function performs the following actions
+ *	- Disable and clear all the interrupts
+ *	- Enable manual slave select
+ *	- Enable the SPI controller
+ */
 static void xspi_init_hw(struct xilinx_spi *xspi)
 {
 	void __iomem *regs_base = xspi->regs;
@@ -183,49 +244,106 @@ static void xspi_init_hw(struct xilinx_spi *xspi)
 		regs_base + XSPI_CR_OFFSET);
 }
 
-static void xilinx_spi_chipselect(struct spi_device *spi, int is_on)
+/**
+ * xspi_chipselect -	Select or deselect the chip select line
+ * @qspi:	Pointer to the spi_device structure
+ * @is_high:	Select(0) or deselect (1) the chip select line
+ *
+ */
+static void xspi_chipselect(struct spi_device *qspi, bool is_high)
 {
-	struct xilinx_spi *xspi = spi_master_get_devdata(spi->master);
-	u16 cr;
+	struct xilinx_spi *xqspi = spi_master_get_devdata(qspi->master);
 	u32 cs;
 
-	if (is_on == BITBANG_CS_INACTIVE) {
-		/* Deselect the slave on the SPI bus */
-		xspi->write_fn(xspi->cs_inactive, xspi->regs + XSPI_SSR_OFFSET);
-		return;
+	if (is_high) {
+		/* Deselect the slave */
+		xqspi->write_fn(xqspi->cs_inactive,
+			xqspi->regs + XSPI_SSR_OFFSET);
+	} else {
+		cs = xqspi->cs_inactive;
+		cs ^= BIT(qspi->chip_select);
+		/* Activate the chip select */
+		xqspi->write_fn(cs, xqspi->regs + XSPI_SSR_OFFSET);
 	}
+}
 
-	/* Set the SPI clock phase and polarity */
-	cr = xspi->read_fn(xspi->regs + XSPI_CR_OFFSET)	& ~XSPI_CR_MODE_MASK;
-	if (spi->mode & SPI_CPHA)
-		cr |= XSPI_CR_CPHA;
-	if (spi->mode & SPI_CPOL)
-		cr |= XSPI_CR_CPOL;
-	if (spi->mode & SPI_LSB_FIRST)
-		cr |= XSPI_CR_LSB_FIRST;
-	if (spi->mode & SPI_LOOP)
-		cr |= XSPI_CR_LOOP;
-	xspi->write_fn(cr, xspi->regs + XSPI_CR_OFFSET);
-
-	/* We do not check spi->max_speed_hz here as the SPI clock
-	 * frequency is not software programmable (the IP block design
-	 * parameter)
-	 */
-
-	cs = xspi->cs_inactive;
-	cs ^= BIT(spi->chip_select);
+/**
+ * xilinx_spi_startup_block - Perform a dummy read as a
+ * work around for the startup block issue in the spi controller.
+ * @xspi:	Pointer to the xilinx_spi structure
+ * @cs_num:	chip select number.
+ *
+ * Perform a dummy read if startup block is enabled in the
+ * spi controller.
+ *
+ * Return:	None
+ */
+static void xilinx_spi_startup_block(struct xilinx_spi *xspi, u32 cs_num)
+{
+	void __iomem *regs_base = xspi->regs;
+	u32 chip_sel, config_reg, status_reg;
 
 	/* Activate the chip select */
-	xspi->write_fn(cs, xspi->regs + XSPI_SSR_OFFSET);
+	chip_sel = xspi->cs_inactive;
+	chip_sel ^= BIT(cs_num);
+	xspi->write_fn(chip_sel, regs_base + XSPI_SSR_OFFSET);
+
+	/* Write ReadId to the TXD register */
+	xspi->write_fn(SPI_READ_ID, regs_base + XSPI_TXD_OFFSET);
+	xspi->write_fn(0x0, regs_base + XSPI_TXD_OFFSET);
+	xspi->write_fn(0x0, regs_base + XSPI_TXD_OFFSET);
+
+	config_reg = xspi->read_fn(regs_base + XSPI_CR_OFFSET);
+	/* Enable master transaction  */
+	config_reg &= ~XSPI_CR_TRANS_INHIBIT;
+	xspi->write_fn(config_reg, regs_base + XSPI_CR_OFFSET);
+
+	status_reg = xspi->read_fn(regs_base + XSPI_SR_OFFSET);
+	while ((status_reg & XSPI_SR_TX_EMPTY_MASK) == 0)
+		status_reg = xspi->read_fn(regs_base + XSPI_SR_OFFSET);
+
+	/* Disable master transaction */
+	config_reg |= XSPI_CR_TRANS_INHIBIT;
+	xspi->write_fn(config_reg, regs_base + XSPI_CR_OFFSET);
+
+	/* Read the RXD Register */
+	status_reg = xspi->read_fn(regs_base + XSPI_SR_OFFSET);
+	while ((status_reg & XSPI_SR_RX_EMPTY_MASK) == 0) {
+		xspi->read_fn(regs_base + XSPI_RXD_OFFSET);
+		status_reg = xspi->read_fn(regs_base + XSPI_SR_OFFSET);
+	}
+
+	xspi_init_hw(xspi);
 }
 
-/* spi_bitbang requires custom setup_transfer() to be defined if there is a
- * custom txrx_bufs().
+/**
+ * xilinx_spi_setup_transfer - Configure SPI controller for specified
+ *			 transfer
+ * @spi:	Pointer to the spi_device structure
+ * @t:	Pointer to the spi_transfer structure which provides
+ *		information about next transfer setup parameters
+ *
+ * Sets the operational mode of QSPI controller for the next QSPI
+ * transfer.
+ *
+ * Return:	0 always
  */
 static int xilinx_spi_setup_transfer(struct spi_device *spi,
 		struct spi_transfer *t)
 {
 	struct xilinx_spi *xspi = spi_master_get_devdata(spi->master);
+	u32 config_reg;
+
+	config_reg = xspi->read_fn(xspi->regs + XSPI_CR_OFFSET);
+	/* Set the QSPI clock phase and clock polarity */
+	config_reg &= ~(XSPI_CR_CPHA | XSPI_CR_CPOL);
+	if (spi->mode & SPI_CPHA)
+		config_reg |= XSPI_CR_CPHA;
+	if (spi->mode & SPI_CPOL)
+		config_reg |= XSPI_CR_CPOL;
+	if (spi->mode & SPI_LSB_FIRST)
+		config_reg |= XSPI_CR_LSB_FIRST;
+	xspi->write_fn(config_reg, xspi->regs + XSPI_CR_OFFSET);
 
 	if (spi->mode & SPI_CS_HIGH)
 		xspi->cs_inactive &= ~BIT(spi->chip_select);
@@ -235,218 +353,425 @@ static int xilinx_spi_setup_transfer(struct spi_device *spi,
 	return 0;
 }
 
-static int xilinx_spi_txrx_bufs(struct spi_device *spi, struct spi_transfer *t)
+/**
+ * xspi_setup -	Configure the SPI controller
+ * @qspi:	Pointer to the spi_device structure
+ *
+ * Sets the operational mode of QSPI controller for the next QSPI
+ * transfer.
+ *
+ * Return:	0 on success; error value otherwise.
+ */
+static int xspi_setup(struct spi_device *qspi)
 {
-	struct xilinx_spi *xspi = spi_master_get_devdata(spi->master);
-	int remaining_words;	/* the number of words left to transfer */
-	bool use_irq = false;
-	u16 cr = 0;
-
-	/* We get here with transmitter inhibited */
-
-	xspi->tx_ptr = t->tx_buf;
-	xspi->rx_ptr = t->rx_buf;
-	remaining_words = t->len / xspi->bytes_per_word;
-
-	if (xspi->irq >= 0 &&  remaining_words > xspi->buffer_size) {
-		u32 isr;
-		use_irq = true;
-		/* Inhibit irq to avoid spurious irqs on tx_empty*/
-		cr = xspi->read_fn(xspi->regs + XSPI_CR_OFFSET);
-		xspi->write_fn(cr | XSPI_CR_TRANS_INHIBIT,
-			       xspi->regs + XSPI_CR_OFFSET);
-		/* ACK old irqs (if any) */
-		isr = xspi->read_fn(xspi->regs + XIPIF_V123B_IISR_OFFSET);
-		if (isr)
-			xspi->write_fn(isr,
-				       xspi->regs + XIPIF_V123B_IISR_OFFSET);
-		/* Enable the global IPIF interrupt */
-		xspi->write_fn(XIPIF_V123B_GINTR_ENABLE,
-				xspi->regs + XIPIF_V123B_DGIER_OFFSET);
-		reinit_completion(&xspi->done);
+	int ret;
+	struct xilinx_spi *xqspi = spi_master_get_devdata(qspi->master);
+
+	if (qspi->master->busy)
+		return -EBUSY;
+
+	ret = pm_runtime_get_sync(xqspi->dev);
+	if (ret < 0)
+		return ret;
+
+	ret = xilinx_spi_setup_transfer(qspi, NULL);
+	pm_runtime_put_sync(xqspi->dev);
+
+	return ret;
+}
+
+/**
+ * xspi_start_transfer - Initiates the SPI transfer
+ * @master:	Pointer to the spi_master structure which provides
+ *		information about the controller.
+ * @qspi:	Pointer to the spi_device structure
+ * @transfer:	Pointer to the spi_transfer structure which provide information
+ *		about next transfer parameters
+ *
+ * This function fills the TX FIFO, starts the SPI transfer, and waits for the
+ * transfer to be completed.
+ *
+ * Return:	Number of bytes transferred in the last transfer
+ */
+
+static int xspi_start_transfer(struct spi_master *master,
+			       struct spi_device *qspi,
+			       struct spi_transfer *transfer)
+{
+	struct xilinx_spi *xqspi = spi_master_get_devdata(master);
+	u32 cr;
+
+	xqspi->tx_ptr = transfer->tx_buf;
+	xqspi->rx_ptr = transfer->rx_buf;
+
+	if (transfer->dummy) {
+		xqspi->bytes_to_transfer = (transfer->len - (transfer->dummy / 8))
+							+ ((transfer->dummy / 8) *
+							xqspi->rx_bus_width);
+		xqspi->bytes_to_receive = (transfer->len - (transfer->dummy / 8))
+							+ ((transfer->dummy / 8) *
+							xqspi->rx_bus_width);
+	} else {
+		xqspi->bytes_to_transfer = transfer->len;
+		xqspi->bytes_to_receive = transfer->len;
 	}
 
-	while (remaining_words) {
-		int n_words, tx_words, rx_words;
-		u32 sr;
-		int stalled;
+	xilinx_spi_setup_transfer(qspi, transfer);
+	cr = xqspi->read_fn(xqspi->regs + XSPI_CR_OFFSET);
+	/* Enable master transaction inhibit */
+	cr |= XSPI_CR_TRANS_INHIBIT;
+	xqspi->write_fn(cr, xqspi->regs + XSPI_CR_OFFSET);
+	xqspi->tx_fifo(xqspi);
+	/* Disable master transaction inhibit */
+	cr &= ~XSPI_CR_TRANS_INHIBIT;
+	xqspi->write_fn(cr, xqspi->regs + XSPI_CR_OFFSET);
+	xqspi->write_fn(XIPIF_V123B_GINTR_ENABLE,
+			xqspi->regs + XIPIF_V123B_DGIER_OFFSET);
+
+	return transfer->len;
+}
 
-		n_words = min(remaining_words, xspi->buffer_size);
+/**
+ * xspi_prepare_transfer_hardware -	Prepares hardware for transfer.
+ * @master:	Pointer to the spi_master structure which provides
+ *		information about the controller.
+ *
+ * This function enables SPI master controller.
+ *
+ * Return:	0 on success; error value otherwise
+ */
+static int xspi_prepare_transfer_hardware(struct spi_master *master)
+{
+	struct xilinx_spi *xqspi = spi_master_get_devdata(master);
 
-		tx_words = n_words;
-		while (tx_words--)
-			xilinx_spi_tx(xspi);
+	u32 cr;
+	int ret;
 
-		/* Start the transfer by not inhibiting the transmitter any
-		 * longer
-		 */
+	ret = pm_runtime_get_sync(xqspi->dev);
+	if (ret < 0)
+		return ret;
 
-		if (use_irq) {
-			xspi->write_fn(cr, xspi->regs + XSPI_CR_OFFSET);
-			wait_for_completion(&xspi->done);
-			/* A transmit has just completed. Process received data
-			 * and check for more data to transmit. Always inhibit
-			 * the transmitter while the Isr refills the transmit
-			 * register/FIFO, or make sure it is stopped if we're
-			 * done.
-			 */
-			xspi->write_fn(cr | XSPI_CR_TRANS_INHIBIT,
-				       xspi->regs + XSPI_CR_OFFSET);
-			sr = XSPI_SR_TX_EMPTY_MASK;
-		} else
-			sr = xspi->read_fn(xspi->regs + XSPI_SR_OFFSET);
-
-		/* Read out all the data from the Rx FIFO */
-		rx_words = n_words;
-		stalled = 10;
-		while (rx_words) {
-			if (rx_words == n_words && !(stalled--) &&
-			    !(sr & XSPI_SR_TX_EMPTY_MASK) &&
-			    (sr & XSPI_SR_RX_EMPTY_MASK)) {
-				dev_err(&spi->dev,
-					"Detected stall. Check C_SPI_MODE and C_SPI_MEMORY\n");
-				xspi_init_hw(xspi);
-				return -EIO;
-			}
-
-			if ((sr & XSPI_SR_TX_EMPTY_MASK) && (rx_words > 1)) {
-				xilinx_spi_rx(xspi);
-				rx_words--;
-				continue;
-			}
-
-			sr = xspi->read_fn(xspi->regs + XSPI_SR_OFFSET);
-			if (!(sr & XSPI_SR_RX_EMPTY_MASK)) {
-				xilinx_spi_rx(xspi);
-				rx_words--;
-			}
-		}
+	cr = xqspi->read_fn(xqspi->regs + XSPI_CR_OFFSET);
+	cr |= XSPI_CR_ENABLE;
+	xqspi->write_fn(cr, xqspi->regs + XSPI_CR_OFFSET);
+
+	return 0;
+}
+
+/**
+ * xspi_unprepare_transfer_hardware -	Relaxes hardware after transfer
+ * @master:	Pointer to the spi_master structure which provides
+ *		information about the controller.
+ *
+ * This function disables the SPI master controller.
+ *
+ * Return:	Always 0
+ */
+static int xspi_unprepare_transfer_hardware(struct spi_master *master)
+{
+	struct xilinx_spi *xqspi = spi_master_get_devdata(master);
+	u32 cr;
+
+	cr = xqspi->read_fn(xqspi->regs + XSPI_CR_OFFSET);
+	cr &= ~XSPI_CR_ENABLE;
+	xqspi->write_fn(cr, xqspi->regs + XSPI_CR_OFFSET);
+
+	pm_runtime_put_sync(xqspi->dev);
 
-		remaining_words -= n_words;
+	return 0;
+}
+
+/**
+ * xilinx_spi_runtime_resume - Runtime resume method for the SPI driver
+ * @dev:	Address of the platform_device structure
+ *
+ * This function enables the clocks
+ *
+ * Return:	0 on success and error value on error
+ */
+static int __maybe_unused xilinx_spi_runtime_resume(struct device *dev)
+{
+	struct spi_master *master = dev_get_drvdata(dev);
+	struct xilinx_spi *xspi = spi_master_get_devdata(master);
+	int ret;
+
+	ret = clk_enable(xspi->axi_clk);
+	if (ret) {
+		dev_err(dev, "Can not enable AXI clock\n");
+		return ret;
+	}
+
+	ret = clk_enable(xspi->axi4_clk);
+	if (ret) {
+		dev_err(dev, "Can not enable AXI4 clock\n");
+		goto clk_disable_axi_clk;
 	}
 
-	if (use_irq) {
-		xspi->write_fn(0, xspi->regs + XIPIF_V123B_DGIER_OFFSET);
-		xspi->write_fn(cr, xspi->regs + XSPI_CR_OFFSET);
+	ret = clk_enable(xspi->spi_clk);
+	if (ret) {
+		dev_err(dev, "Can not enable SPI clock\n");
+		goto clk_disable_axi4_clk;
 	}
 
-	return t->len;
+	return 0;
+
+clk_disable_axi4_clk:
+	clk_disable(xspi->axi4_clk);
+clk_disable_axi_clk:
+	clk_disable(xspi->axi_clk);
+
+	return ret;
 }
 
+/**
+ * xilinx_spi_runtime_suspend - Runtime suspend method for the SPI driver
+ * @dev:	Address of the platform_device structure
+ *
+ * This function disables the clocks
+ *
+ * Return:	Always 0
+ */
+static int __maybe_unused xilinx_spi_runtime_suspend(struct device *dev)
+{
+	struct spi_master *master = dev_get_drvdata(dev);
+	struct xilinx_spi *xspi = spi_master_get_devdata(master);
 
-/* This driver supports single master mode only. Hence Tx FIFO Empty
- * is the only interrupt we care about.
- * Receive FIFO Overrun, Transmit FIFO Underrun, Mode Fault, and Slave Mode
- * Fault are not to happen.
+	clk_disable(xspi->axi_clk);
+	clk_disable(xspi->axi4_clk);
+	clk_disable(xspi->spi_clk);
+
+	return 0;
+}
+
+/**
+ * xilinx_spi_resume - Resume method for the SPI driver
+ * @dev:	Address of the platform_device structure
+ *
+ * The function starts the SPI driver queue and initializes the SPI
+ * controller
+ *
+ * Return:	0 on success; error value otherwise
  */
-static irqreturn_t xilinx_spi_irq(int irq, void *dev_id)
+static int __maybe_unused xilinx_spi_resume(struct device *dev)
 {
-	struct xilinx_spi *xspi = dev_id;
-	u32 ipif_isr;
+	struct spi_master *master = dev_get_drvdata(dev);
+	struct xilinx_spi *xspi = spi_master_get_devdata(master);
+	int ret = 0;
 
-	/* Get the IPIF interrupts, and clear them immediately */
-	ipif_isr = xspi->read_fn(xspi->regs + XIPIF_V123B_IISR_OFFSET);
-	xspi->write_fn(ipif_isr, xspi->regs + XIPIF_V123B_IISR_OFFSET);
+	if (!pm_runtime_suspended(dev)) {
+		ret = xilinx_spi_runtime_resume(dev);
+		if (ret < 0)
+			return ret;
+	}
 
-	if (ipif_isr & XSPI_INTR_TX_EMPTY) {	/* Transmission completed */
-		complete(&xspi->done);
-		return IRQ_HANDLED;
+	ret = spi_master_resume(master);
+	if (ret < 0) {
+		clk_disable(xspi->axi_clk);
+		clk_disable(xspi->axi4_clk);
+		clk_disable(xspi->spi_clk);
 	}
 
-	return IRQ_NONE;
+	return ret;
 }
 
-static int xilinx_spi_find_buffer_size(struct xilinx_spi *xspi)
+/**
+ * xilinx_spi_suspend - Suspend method for the SPI driver
+ * @dev:	Address of the platform_device structure
+ *
+ * This function stops the SPI driver queue and disables the SPI controller
+ *
+ * Return:	Always 0
+ */
+static int __maybe_unused xilinx_spi_suspend(struct device *dev)
 {
-	u8 sr;
-	int n_words = 0;
+	struct spi_master *master = dev_get_drvdata(dev);
+	int ret = 0;
 
-	/*
-	 * Before the buffer_size detection we reset the core
-	 * to make sure we start with a clean state.
-	 */
-	xspi->write_fn(XIPIF_V123B_RESET_MASK,
-		xspi->regs + XIPIF_V123B_RESETR_OFFSET);
+	ret = spi_master_suspend(master);
+	if (ret)
+		return ret;
+
+	if (!pm_runtime_suspended(dev))
+		xilinx_spi_runtime_suspend(dev);
 
-	/* Fill the Tx FIFO with as many words as possible */
-	do {
-		xspi->write_fn(0, xspi->regs + XSPI_TXD_OFFSET);
-		sr = xspi->read_fn(xspi->regs + XSPI_SR_OFFSET);
-		n_words++;
-	} while (!(sr & XSPI_SR_TX_FULL_MASK));
+	xspi_unprepare_transfer_hardware(master);
 
-	return n_words;
+	return ret;
 }
 
-static const struct of_device_id xilinx_spi_of_match[] = {
-	{ .compatible = "xlnx,axi-quad-spi-1.00.a", },
-	{ .compatible = "xlnx,xps-spi-2.00.a", },
-	{ .compatible = "xlnx,xps-spi-2.00.b", },
-	{}
+static const struct dev_pm_ops xilinx_spi_dev_pm_ops = {
+	SET_RUNTIME_PM_OPS(xilinx_spi_runtime_suspend,
+			   xilinx_spi_runtime_resume, NULL)
+	SET_SYSTEM_SLEEP_PM_OPS(xilinx_spi_suspend, xilinx_spi_resume)
 };
-MODULE_DEVICE_TABLE(of, xilinx_spi_of_match);
 
+/* This driver supports single master mode only. Hence Tx FIFO Empty
+ * is the only interrupt we care about.
+ * Receive FIFO Overrun, Transmit FIFO Underrun, Mode Fault, and Slave Mode
+ * Fault are not to happen.
+ */
+static irqreturn_t xilinx_spi_irq(int irq, void *dev_id)
+{
+	struct spi_master *master = dev_id;
+	struct xilinx_spi *xspi = spi_master_get_devdata(dev_id);
+	u32 ipif_isr;
+	irqreturn_t status = IRQ_NONE;
+
+	/* Get the IPIF interrupts, and clear them immediately */
+	ipif_isr = xspi->read_fn(xspi->regs + XIPIF_V123B_IISR_OFFSET);
+	xspi->write_fn(ipif_isr, xspi->regs + XIPIF_V123B_IISR_OFFSET);
+	if (ipif_isr & XSPI_INTR_TX_EMPTY)  {
+		/* Transmission completed */
+		xspi->rx_fifo(xspi);
+		if (xspi->bytes_to_transfer) {
+			/* There is more data to send */
+			xspi->tx_fifo(xspi);
+		}
+		status = IRQ_HANDLED;
+	}
+
+	if (!xspi->bytes_to_receive && !xspi->bytes_to_transfer) {
+		spi_finalize_current_transfer(master);
+		/* Disable the interrupts here. */
+		xspi->write_fn(0x0, xspi->regs + XIPIF_V123B_DGIER_OFFSET);
+	}
+
+	return status;
+}
 static int xilinx_spi_probe(struct platform_device *pdev)
 {
 	struct xilinx_spi *xspi;
-	struct xspi_platform_data *pdata;
 	struct resource *res;
-	int ret, num_cs = 0, bits_per_word;
+	int ret;
+	u32 num_cs = 0, bits_per_word = 8;
+	u32 cs_num;
 	struct spi_master *master;
-	u32 tmp;
-	u8 i;
+	struct device_node *nc;
+	u32 tmp, rx_bus_width, fifo_size;
+	bool startup_block;
 
-	pdata = dev_get_platdata(&pdev->dev);
-	if (pdata) {
-		num_cs = pdata->num_chipselect;
-		bits_per_word = pdata->bits_per_word;
-	} else {
-		of_property_read_u32(pdev->dev.of_node, "xlnx,num-ss-bits",
-					  &num_cs);
-		ret = of_property_read_u32(pdev->dev.of_node,
-					   "xlnx,num-transfer-bits",
-					   &bits_per_word);
-		if (ret)
-			bits_per_word = 8;
-	}
-
-	if (!num_cs) {
-		dev_err(&pdev->dev,
-			"Missing slave select configuration data\n");
-		return -EINVAL;
-	}
+	if (of_property_read_u32(pdev->dev.of_node, "num-cs", &num_cs))
+		dev_info(&pdev->dev,
+			 "Missing num-cs optional property, assuming default as <1>\n");
+	if (!num_cs)
+		num_cs = 1;
 
 	if (num_cs > XILINX_SPI_MAX_CS) {
 		dev_err(&pdev->dev, "Invalid number of spi slaves\n");
 		return -EINVAL;
 	}
 
+	startup_block = of_property_read_bool(pdev->dev.of_node,
+					      "xlnx,startup-block");
 	master = spi_alloc_master(&pdev->dev, sizeof(struct xilinx_spi));
 	if (!master)
 		return -ENODEV;
 
-	/* the spi->mode bits understood by this driver: */
-	master->mode_bits = SPI_CPOL | SPI_CPHA | SPI_LSB_FIRST | SPI_LOOP |
-			    SPI_CS_HIGH;
-
 	xspi = spi_master_get_devdata(master);
-	xspi->cs_inactive = 0xffffffff;
-	xspi->bitbang.master = master;
-	xspi->bitbang.chipselect = xilinx_spi_chipselect;
-	xspi->bitbang.setup_transfer = xilinx_spi_setup_transfer;
-	xspi->bitbang.txrx_bufs = xilinx_spi_txrx_bufs;
-	init_completion(&xspi->done);
-
+	master->dev.of_node = pdev->dev.of_node;
+	platform_set_drvdata(pdev, master);
 	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
 	xspi->regs = devm_ioremap_resource(&pdev->dev, res);
 	if (IS_ERR(xspi->regs)) {
 		ret = PTR_ERR(xspi->regs);
 		goto put_master;
 	}
+	ret = of_property_read_u32(pdev->dev.of_node, "fifo-size",
+				   &fifo_size);
+	if (ret < 0) {
+		dev_err(&pdev->dev,
+			"Missing fifo size\n");
+		return -EINVAL;
+	}
+	if (of_property_read_u32(pdev->dev.of_node, "bits-per-word",
+				 &bits_per_word))
+		dev_info(&pdev->dev,
+			 "Missing bits-per-word optional property, assuming default as <8>\n");
+
+	xspi->rx_bus_width = XSPI_ONE_BITS_PER_WORD;
+	for_each_available_child_of_node(pdev->dev.of_node, nc) {
+		if (startup_block) {
+			ret = of_property_read_u32(nc, "reg",
+						   &cs_num);
+			if (ret < 0)
+				return -EINVAL;
+		}
+		ret = of_property_read_u32(nc, "spi-rx-bus-width",
+					   &rx_bus_width);
+		if (!ret) {
+			xspi->rx_bus_width = rx_bus_width;
+			break;
+		}
+	}
 
-	master->bus_num = pdev->id;
-	master->num_chipselect = num_cs;
-	master->dev.of_node = pdev->dev.of_node;
+	xspi->axi_clk = devm_clk_get(&pdev->dev, "axi_clk");
+	if (IS_ERR(xspi->axi_clk)) {
+		if (PTR_ERR(xspi->axi_clk) != -ENOENT) {
+			ret = PTR_ERR(xspi->axi_clk);
+			goto put_master;
+		}
+
+		/*
+		 * Clock framework support is optional, continue on,
+		 * anyways if we don't find a matching clock
+		 */
+		xspi->axi_clk = NULL;
+	}
+
+	ret = clk_prepare(xspi->axi_clk);
+	if (ret) {
+		dev_err(&pdev->dev, "Failed to prepare AXI clock\n");
+		goto put_master;
+	}
+
+	xspi->axi4_clk = devm_clk_get(&pdev->dev, "axi4_clk");
+	if (IS_ERR(xspi->axi4_clk)) {
+		if (PTR_ERR(xspi->axi4_clk) != -ENOENT) {
+			ret = PTR_ERR(xspi->axi4_clk);
+			goto clk_unprepare_axi_clk;
+		}
+
+		/*
+		 * Clock framework support is optional, continue on,
+		 * anyways if we don't find a matching clock
+		 */
+		xspi->axi4_clk = NULL;
+	}
+
+	ret = clk_prepare(xspi->axi4_clk);
+	if (ret) {
+		dev_err(&pdev->dev, "Failed to prepare AXI4 clock\n");
+		goto clk_unprepare_axi_clk;
+	}
+
+	xspi->spi_clk = devm_clk_get(&pdev->dev, "spi_clk");
+	if (IS_ERR(xspi->spi_clk)) {
+		if (PTR_ERR(xspi->spi_clk) != -ENOENT) {
+			ret = PTR_ERR(xspi->spi_clk);
+			goto clk_unprepare_axi4_clk;
+		}
+
+		/*
+		 * Clock framework support is optional, continue on,
+		 * anyways if we don't find a matching clock
+		 */
+		xspi->spi_clk = NULL;
+	}
+
+	ret = clk_prepare(xspi->spi_clk);
+	if (ret) {
+		dev_err(&pdev->dev, "Failed to prepare SPI clock\n");
+		goto clk_unprepare_axi4_clk;
+	}
+
+	pm_runtime_set_autosuspend_delay(&pdev->dev, SPI_AUTOSUSPEND_TIMEOUT);
+	pm_runtime_use_autosuspend(&pdev->dev);
+	pm_runtime_enable(&pdev->dev);
+	ret = pm_runtime_get_sync(&pdev->dev);
+	if (ret < 0)
+		goto clk_unprepare_all;
+
+	xspi->dev = &pdev->dev;
 
 	/*
 	 * Detect endianess on the IP via loop bit in CR. Detection
@@ -466,61 +791,112 @@ static int xilinx_spi_probe(struct platform_device *pdev)
 		xspi->write_fn = xspi_write32_be;
 	}
 
-	master->bits_per_word_mask = SPI_BPW_MASK(bits_per_word);
-	xspi->bytes_per_word = bits_per_word / 8;
-	xspi->buffer_size = xilinx_spi_find_buffer_size(xspi);
-
+	xspi->buffer_size = fifo_size;
 	xspi->irq = platform_get_irq(pdev, 0);
 	if (xspi->irq < 0 && xspi->irq != -ENXIO) {
 		ret = xspi->irq;
-		goto put_master;
+		goto clk_unprepare_all;
 	} else if (xspi->irq >= 0) {
 		/* Register for SPI Interrupt */
-		ret = devm_request_irq(&pdev->dev, xspi->irq, xilinx_spi_irq, 0,
-				dev_name(&pdev->dev), xspi);
+		ret = devm_request_irq(&pdev->dev, xspi->irq, xilinx_spi_irq,
+				       0, dev_name(&pdev->dev), master);
 		if (ret)
-			goto put_master;
+			goto clk_unprepare_all;
 	}
 
 	/* SPI controller initializations */
 	xspi_init_hw(xspi);
 
-	ret = spi_bitbang_start(&xspi->bitbang);
-	if (ret) {
-		dev_err(&pdev->dev, "spi_bitbang_start FAILED\n");
-		goto put_master;
+	pm_runtime_put(&pdev->dev);
+
+	master->bus_num = pdev->id;
+	master->num_chipselect = num_cs;
+	master->setup = xspi_setup;
+	master->set_cs = xspi_chipselect;
+	master->transfer_one = xspi_start_transfer;
+	master->prepare_transfer_hardware = xspi_prepare_transfer_hardware;
+	master->unprepare_transfer_hardware = xspi_unprepare_transfer_hardware;
+	master->bits_per_word_mask = SPI_BPW_MASK(8);
+	master->mode_bits = SPI_CPOL | SPI_CPHA | SPI_CS_HIGH;
+
+	xspi->bytes_per_word = bits_per_word / 8;
+	xspi->tx_fifo = xspi_fill_tx_fifo_8;
+	xspi->rx_fifo = xspi_read_rx_fifo_8;
+	if (xspi->rx_bus_width == XSPI_RX_ONE_WIRE) {
+		if (xspi->bytes_per_word == XSPI_TWO_BITS_PER_WORD) {
+			xspi->tx_fifo = xspi_fill_tx_fifo_16;
+			xspi->rx_fifo = xspi_read_rx_fifo_16;
+		} else if (xspi->bytes_per_word == XSPI_FOUR_BITS_PER_WORD) {
+			xspi->tx_fifo = xspi_fill_tx_fifo_32;
+			xspi->rx_fifo = xspi_read_rx_fifo_32;
+		}
+	} else if (xspi->rx_bus_width == XSPI_RX_FOUR_WIRE) {
+		master->mode_bits |= SPI_TX_QUAD | SPI_RX_QUAD;
+	} else {
+		dev_err(&pdev->dev, "Dual Mode not supported\n");
+		goto clk_unprepare_all;
 	}
+	xspi->cs_inactive = 0xffffffff;
 
-	dev_info(&pdev->dev, "at %pR, irq=%d\n", res, xspi->irq);
+	/*
+	 * This is the work around for the startup block issue in
+	 * the spi controller. SPI clock is passing through STARTUP
+	 * block to FLASH. STARTUP block don't provide clock as soon
+	 * as QSPI provides command. So first command fails.
+	 */
+	if (startup_block)
+		xilinx_spi_startup_block(xspi, cs_num);
 
-	if (pdata) {
-		for (i = 0; i < pdata->num_devices; i++)
-			spi_new_device(master, pdata->devices + i);
+	ret = spi_register_master(master);
+	if (ret) {
+		dev_err(&pdev->dev, "spi_register_master failed\n");
+		goto clk_unprepare_all;
 	}
 
-	platform_set_drvdata(pdev, master);
-	return 0;
+	return ret;
 
+clk_unprepare_all:
+	pm_runtime_disable(&pdev->dev);
+	pm_runtime_set_suspended(&pdev->dev);
+	clk_unprepare(xspi->spi_clk);
+clk_unprepare_axi4_clk:
+	clk_unprepare(xspi->axi4_clk);
+clk_unprepare_axi_clk:
+	clk_unprepare(xspi->axi_clk);
 put_master:
 	spi_master_put(master);
 
 	return ret;
 }
 
+/**
+ * xilinx_spi_remove -	Remove method for the SPI driver
+ * @pdev:	Pointer to the platform_device structure
+ *
+ * This function is called if a device is physically removed from the system or
+ * if the driver module is being unloaded. It frees all resources allocated to
+ * the device.
+ *
+ * Return:	0 Always
+ */
 static int xilinx_spi_remove(struct platform_device *pdev)
 {
 	struct spi_master *master = platform_get_drvdata(pdev);
 	struct xilinx_spi *xspi = spi_master_get_devdata(master);
 	void __iomem *regs_base = xspi->regs;
 
-	spi_bitbang_stop(&xspi->bitbang);
-
 	/* Disable all the interrupts just in case */
 	xspi->write_fn(0, regs_base + XIPIF_V123B_IIER_OFFSET);
 	/* Disable the global IPIF interrupt */
 	xspi->write_fn(0, regs_base + XIPIF_V123B_DGIER_OFFSET);
 
-	spi_master_put(xspi->bitbang.master);
+	pm_runtime_disable(&pdev->dev);
+
+	clk_disable_unprepare(xspi->axi_clk);
+	clk_disable_unprepare(xspi->axi4_clk);
+	clk_disable_unprepare(xspi->spi_clk);
+
+	spi_unregister_master(master);
 
 	return 0;
 }
@@ -528,12 +904,21 @@ static int xilinx_spi_remove(struct platform_device *pdev)
 /* work with hotplug and coldplug */
 MODULE_ALIAS("platform:" XILINX_SPI_NAME);
 
+static const struct of_device_id xilinx_spi_of_match[] = {
+	{ .compatible = "xlnx,axi-quad-spi-1.00.a", },
+	{ .compatible = "xlnx,xps-spi-2.00.a", },
+	{ .compatible = "xlnx,xps-spi-2.00.b", },
+	{}
+};
+MODULE_DEVICE_TABLE(of, xilinx_spi_of_match);
+
 static struct platform_driver xilinx_spi_driver = {
 	.probe = xilinx_spi_probe,
 	.remove = xilinx_spi_remove,
 	.driver = {
 		.name = XILINX_SPI_NAME,
 		.of_match_table = xilinx_spi_of_match,
+		.pm = &xilinx_spi_dev_pm_ops,
 	},
 };
 module_platform_driver(xilinx_spi_driver);
diff --git a/drivers/spi/spi-zynq-qspi.c b/drivers/spi/spi-zynq-qspi.c
index 13c0b15fe..2901da8c3 100644
--- a/drivers/spi/spi-zynq-qspi.c
+++ b/drivers/spi/spi-zynq-qspi.c
@@ -62,6 +62,7 @@
 #define ZYNQ_QSPI_CONFIG_BAUD_DIV_MAX	GENMASK(2, 0) /* Baud rate maximum */
 #define ZYNQ_QSPI_CONFIG_BAUD_DIV_SHIFT	3 /* Baud rate divisor shift */
 #define ZYNQ_QSPI_CONFIG_PCS		BIT(10) /* Peripheral Chip Select */
+#define ZYNQ_QSPI_SS_SHIFT		10 /* Slave Select field shift in CR */
 
 /*
  * QSPI Interrupt Registers bit Masks
@@ -129,6 +130,9 @@
  * @tx_bytes:		Number of bytes left to transfer
  * @rx_bytes:		Number of bytes left to receive
  * @data_completion:	completion structure
+ * @is_dual:		Flag to indicate whether dual flash memories are used
+ * @is_stripe:		Flag to indicate if data needs to be split between flashes
+ *			(Used in dual parallel configuration)
  */
 struct zynq_qspi {
 	struct device *dev;
@@ -141,6 +145,8 @@ struct zynq_qspi {
 	int tx_bytes;
 	int rx_bytes;
 	struct completion data_completion;
+	u32 is_dual;
+	bool is_stripe;
 };
 
 /*
@@ -185,13 +191,7 @@ static void zynq_qspi_init_hw(struct zynq_qspi *xqspi, unsigned int num_cs)
 	zynq_qspi_write(xqspi, ZYNQ_QSPI_ENABLE_OFFSET, 0);
 	zynq_qspi_write(xqspi, ZYNQ_QSPI_IDIS_OFFSET, ZYNQ_QSPI_IXR_ALL_MASK);
 
-	/* Disable linear mode as the boot loader may have used it */
-	config_reg = 0;
-	/* At the same time, enable dual mode if more than 1 CS is available */
-	if (num_cs > 1)
-		config_reg |= ZYNQ_QSPI_LCFG_TWO_MEM;
-
-	zynq_qspi_write(xqspi, ZYNQ_QSPI_LINEAR_CFG_OFFSET, config_reg);
+	zynq_qspi_write(xqspi, ZYNQ_QSPI_LINEAR_CFG_OFFSET, 0);
 
 	/* Clear the RX FIFO */
 	while (zynq_qspi_read(xqspi, ZYNQ_QSPI_STATUS_OFFSET) &
@@ -217,7 +217,20 @@ static void zynq_qspi_init_hw(struct zynq_qspi *xqspi, unsigned int num_cs)
 			ZYNQ_QSPI_RX_THRESHOLD);
 	zynq_qspi_write(xqspi, ZYNQ_QSPI_TX_THRESH_OFFSET,
 			ZYNQ_QSPI_TX_THRESHOLD);
-
+	if (xqspi->is_dual)
+		/* Enable two memories on separate buses */
+		zynq_qspi_write(xqspi, ZYNQ_QSPI_LINEAR_CFG_OFFSET,
+				(ZYNQ_QSPI_LCFG_TWO_MEM |
+				ZYNQ_QSPI_LCFG_SEP_BUS |
+				(1 << ZYNQ_QSPI_LCFG_DUMMY_SHIFT) |
+				ZYNQ_QSPI_FAST_READ_QOUT_CODE));
+#ifdef CONFIG_SPI_ZYNQ_QSPI_DUAL_STACKED
+	/* Enable two memories on shared bus */
+	zynq_qspi_write(xqspi, ZYNQ_QSPI_LINEAR_CFG_OFFSET,
+			(ZYNQ_QSPI_LCFG_TWO_MEM |
+			(1 << ZYNQ_QSPI_LCFG_DUMMY_SHIFT) |
+			ZYNQ_QSPI_FAST_READ_QOUT_CODE));
+#endif
 	zynq_qspi_write(xqspi, ZYNQ_QSPI_ENABLE_OFFSET,
 			ZYNQ_QSPI_ENABLE_ENABLE_MASK);
 }
@@ -227,13 +240,6 @@ static bool zynq_qspi_supports_op(struct spi_mem *mem,
 {
 	if (!spi_mem_default_supports_op(mem, op))
 		return false;
-
-	/*
-	 * The number of address bytes should be equal to or less than 3 bytes.
-	 */
-	if (op->addr.nbytes > 3)
-		return false;
-
 	return true;
 }
 
@@ -245,11 +251,15 @@ static bool zynq_qspi_supports_op(struct spi_mem *mem,
 static void zynq_qspi_rxfifo_op(struct zynq_qspi *xqspi, unsigned int size)
 {
 	u32 data;
+	unsigned int xsize;
 
 	data = zynq_qspi_read(xqspi, ZYNQ_QSPI_RXD_OFFSET);
 
 	if (xqspi->rxbuf) {
-		memcpy(xqspi->rxbuf, ((u8 *)&data) + 4 - size, size);
+		xsize = size;
+		if (xqspi->is_dual && xqspi->is_stripe && (size % 2))
+			xsize++;
+		memcpy(xqspi->rxbuf, ((u8 *)&data) + 4 - xsize, size);
 		xqspi->rxbuf += size;
 	}
 
@@ -269,6 +279,7 @@ static void zynq_qspi_txfifo_op(struct zynq_qspi *xqspi, unsigned int size)
 		ZYNQ_QSPI_TXD_00_01_OFFSET, ZYNQ_QSPI_TXD_00_10_OFFSET,
 		ZYNQ_QSPI_TXD_00_11_OFFSET, ZYNQ_QSPI_TXD_00_00_OFFSET };
 	u32 data;
+	unsigned int xsize;
 
 	if (xqspi->txbuf) {
 		data = 0xffffffff;
@@ -279,7 +290,11 @@ static void zynq_qspi_txfifo_op(struct zynq_qspi *xqspi, unsigned int size)
 	}
 
 	xqspi->tx_bytes -= size;
-	zynq_qspi_write(xqspi, offset[size - 1], data);
+	xsize = size;
+	if (xqspi->is_dual && xqspi->is_stripe && (size % 2))
+		xsize++;
+
+	zynq_qspi_write(xqspi, offset[xsize - 1], data);
 }
 
 /**
@@ -292,25 +307,29 @@ static void zynq_qspi_chipselect(struct spi_device *spi, bool assert)
 	struct spi_controller *ctlr = spi->master;
 	struct zynq_qspi *xqspi = spi_controller_get_devdata(ctlr);
 	u32 config_reg;
+#ifdef CONFIG_SPI_ZYNQ_QSPI_DUAL_STACKED
+	u32 lqspi_cfg_reg;
+#endif
 
-	/* Select the lower (CS0) or upper (CS1) memory */
-	if (ctlr->num_chipselect > 1) {
-		config_reg = zynq_qspi_read(xqspi, ZYNQ_QSPI_LINEAR_CFG_OFFSET);
-		if (!spi->chip_select)
-			config_reg &= ~ZYNQ_QSPI_LCFG_U_PAGE;
-		else
-			config_reg |= ZYNQ_QSPI_LCFG_U_PAGE;
-
-		zynq_qspi_write(xqspi, ZYNQ_QSPI_LINEAR_CFG_OFFSET, config_reg);
-	}
+	config_reg = zynq_qspi_read(xqspi, ZYNQ_QSPI_CONFIG_OFFSET);
 
+#ifdef CONFIG_SPI_ZYNQ_QSPI_DUAL_STACKED
+	lqspi_cfg_reg = zynq_qspi_read(xqspi, ZYNQ_QSPI_LINEAR_CFG_OFFSET);
+		if (spi->master->flags & SPI_MASTER_U_PAGE)
+			lqspi_cfg_reg |= ZYNQ_QSPI_LCFG_U_PAGE;
+		else
+			lqspi_cfg_reg &= ~ZYNQ_QSPI_LCFG_U_PAGE;
+		zynq_qspi_write(xqspi, ZYNQ_QSPI_LINEAR_CFG_OFFSET,
+				lqspi_cfg_reg);
+#endif
 	/* Ground the line to assert the CS */
-	config_reg = zynq_qspi_read(xqspi, ZYNQ_QSPI_CONFIG_OFFSET);
-	if (assert)
+	if (assert) {
 		config_reg &= ~ZYNQ_QSPI_CONFIG_PCS;
-	else
+		config_reg |= (((~(BIT(spi->chip_select))) <<
+			       ZYNQ_QSPI_SS_SHIFT) & ZYNQ_QSPI_CONFIG_PCS);
+	} else {
 		config_reg |= ZYNQ_QSPI_CONFIG_PCS;
-
+	}
 	zynq_qspi_write(xqspi, ZYNQ_QSPI_CONFIG_OFFSET, config_reg);
 }
 
@@ -367,7 +386,7 @@ static int zynq_qspi_config_op(struct zynq_qspi *xqspi, struct spi_device *spi)
 }
 
 /**
- * zynq_qspi_setup - Configure the QSPI controller
+ * zynq_qspi_setup_op - Configure the QSPI controller
  * @spi:	Pointer to the spi_device structure
  *
  * Sets the operational mode of QSPI controller for the next QSPI transfer, baud
@@ -545,7 +564,7 @@ static int zynq_qspi_exec_mem_op(struct spi_mem *mem,
 		zynq_qspi_write_op(xqspi, ZYNQ_QSPI_FIFO_DEPTH, true);
 		zynq_qspi_write(xqspi, ZYNQ_QSPI_IEN_OFFSET,
 				ZYNQ_QSPI_IXR_RXTX_MASK);
-		if (!wait_for_completion_timeout(&xqspi->data_completion,
+		if (!wait_for_completion_interruptible_timeout(&xqspi->data_completion,
 							       msecs_to_jiffies(1000)))
 			err = -ETIMEDOUT;
 	}
@@ -563,16 +582,13 @@ static int zynq_qspi_exec_mem_op(struct spi_mem *mem,
 		zynq_qspi_write_op(xqspi, ZYNQ_QSPI_FIFO_DEPTH, true);
 		zynq_qspi_write(xqspi, ZYNQ_QSPI_IEN_OFFSET,
 				ZYNQ_QSPI_IXR_RXTX_MASK);
-		if (!wait_for_completion_timeout(&xqspi->data_completion,
+		if (!wait_for_completion_interruptible_timeout(&xqspi->data_completion,
 							       msecs_to_jiffies(1000)))
 			err = -ETIMEDOUT;
 	}
 
 	if (op->dummy.nbytes) {
 		tmpbuf = kzalloc(op->dummy.nbytes, GFP_KERNEL);
-		if (!tmpbuf)
-			return -ENOMEM;
-
 		memset(tmpbuf, 0xff, op->dummy.nbytes);
 		reinit_completion(&xqspi->data_completion);
 		xqspi->txbuf = tmpbuf;
@@ -582,7 +598,7 @@ static int zynq_qspi_exec_mem_op(struct spi_mem *mem,
 		zynq_qspi_write_op(xqspi, ZYNQ_QSPI_FIFO_DEPTH, true);
 		zynq_qspi_write(xqspi, ZYNQ_QSPI_IEN_OFFSET,
 				ZYNQ_QSPI_IXR_RXTX_MASK);
-		if (!wait_for_completion_timeout(&xqspi->data_completion,
+		if (!wait_for_completion_interruptible_timeout(&xqspi->data_completion,
 							       msecs_to_jiffies(1000)))
 			err = -ETIMEDOUT;
 
@@ -590,6 +606,8 @@ static int zynq_qspi_exec_mem_op(struct spi_mem *mem,
 	}
 
 	if (op->data.nbytes) {
+		if (xqspi->is_dual)
+			xqspi->is_stripe = update_stripe(op);
 		reinit_completion(&xqspi->data_completion);
 		if (op->data.dir == SPI_MEM_DATA_OUT) {
 			xqspi->txbuf = (u8 *)op->data.buf.out;
@@ -606,10 +624,13 @@ static int zynq_qspi_exec_mem_op(struct spi_mem *mem,
 		zynq_qspi_write_op(xqspi, ZYNQ_QSPI_FIFO_DEPTH, true);
 		zynq_qspi_write(xqspi, ZYNQ_QSPI_IEN_OFFSET,
 				ZYNQ_QSPI_IXR_RXTX_MASK);
-		if (!wait_for_completion_timeout(&xqspi->data_completion,
+		if (!wait_for_completion_interruptible_timeout(&xqspi->data_completion,
 							       msecs_to_jiffies(1000)))
 			err = -ETIMEDOUT;
 	}
+	if (xqspi->is_stripe)
+		xqspi->is_stripe = false;
+
 	zynq_qspi_chipselect(mem->spi, false);
 
 	return err;
@@ -650,6 +671,11 @@ static int zynq_qspi_probe(struct platform_device *pdev)
 		goto remove_master;
 	}
 
+	if (of_property_read_u32(pdev->dev.of_node, "is-dual",
+				 &xqspi->is_dual)) {
+		dev_warn(&pdev->dev, "couldn't determine configuration info");
+		dev_warn(&pdev->dev, "about dual memories. defaulting to single memory\n");
+	}
 	xqspi->pclk = devm_clk_get(&pdev->dev, "pclk");
 	if (IS_ERR(xqspi->pclk)) {
 		dev_err(&pdev->dev, "pclk clock not found.\n");
@@ -681,14 +707,14 @@ static int zynq_qspi_probe(struct platform_device *pdev)
 	xqspi->irq = platform_get_irq(pdev, 0);
 	if (xqspi->irq <= 0) {
 		ret = -ENXIO;
-		goto clk_dis_all;
+		goto remove_master;
 	}
 	ret = devm_request_irq(&pdev->dev, xqspi->irq, zynq_qspi_irq,
 			       0, pdev->name, xqspi);
 	if (ret != 0) {
 		ret = -ENXIO;
 		dev_err(&pdev->dev, "request_irq failed\n");
-		goto clk_dis_all;
+		goto remove_master;
 	}
 
 	ret = of_property_read_u32(np, "num-cs",
@@ -696,14 +722,13 @@ static int zynq_qspi_probe(struct platform_device *pdev)
 	if (ret < 0) {
 		ctlr->num_chipselect = 1;
 	} else if (num_cs > ZYNQ_QSPI_MAX_NUM_CS) {
-		ret = -EINVAL;
 		dev_err(&pdev->dev, "only 2 chip selects are available\n");
-		goto clk_dis_all;
+		goto remove_master;
 	} else {
 		ctlr->num_chipselect = num_cs;
 	}
 
-	ctlr->mode_bits =  SPI_RX_DUAL | SPI_RX_QUAD |
+	ctlr->mode_bits = SPI_CPOL | SPI_CPHA | SPI_RX_DUAL | SPI_RX_QUAD |
 			    SPI_TX_DUAL | SPI_TX_QUAD;
 	ctlr->mem_ops = &zynq_qspi_mem_ops;
 	ctlr->setup = zynq_qspi_setup_op;
diff --git a/drivers/spi/spi-zynqmp-gqspi.c b/drivers/spi/spi-zynqmp-gqspi.c
index 3d3ac4824..c06f8471c 100644
--- a/drivers/spi/spi-zynqmp-gqspi.c
+++ b/drivers/spi/spi-zynqmp-gqspi.c
@@ -16,6 +16,7 @@
 #include <linux/module.h>
 #include <linux/of_irq.h>
 #include <linux/of_address.h>
+#include <linux/of_device.h>
 #include <linux/platform_device.h>
 #include <linux/pm_runtime.h>
 #include <linux/spi/spi.h>
@@ -34,6 +35,7 @@
 #define GQSPI_RXD_OFST			0x00000120
 #define GQSPI_TX_THRESHOLD_OFST		0x00000128
 #define GQSPI_RX_THRESHOLD_OFST		0x0000012C
+#define IOU_TAPDLY_BYPASS_OFST		0x0000003C
 #define GQSPI_LPBK_DLY_ADJ_OFST		0x00000138
 #define GQSPI_GEN_FIFO_OFST		0x00000140
 #define GQSPI_SEL_OFST			0x00000144
@@ -48,6 +50,7 @@
 #define GQSPI_QSPIDMA_DST_I_MASK_OFST	0x00000820
 #define GQSPI_QSPIDMA_DST_ADDR_OFST	0x00000800
 #define GQSPI_QSPIDMA_DST_ADDR_MSB_OFST 0x00000828
+#define GQSPI_DATA_DLY_ADJ_OFST		0x000001F8
 
 /* GQSPI register bit masks */
 #define GQSPI_SEL_MASK				0x00000001
@@ -133,10 +136,43 @@
 #define GQSPI_SELECT_MODE_QUADSPI	0x4
 #define GQSPI_DMA_UNALIGN		0x3
 #define GQSPI_DEFAULT_NUM_CS	1	/* Default number of chip selects */
+#define GQSPI_RX_BUS_WIDTH_QUAD		0x4
+#define GQSPI_RX_BUS_WIDTH_DUAL		0x2
+#define GQSPI_RX_BUS_WIDTH_SINGLE	0x1
+#define GQSPI_TX_BUS_WIDTH_QUAD		0x4
+#define GQSPI_TX_BUS_WIDTH_DUAL		0x2
+#define GQSPI_TX_BUS_WIDTH_SINGLE	0x1
+#define GQSPI_LPBK_DLY_ADJ_LPBK_SHIFT	5
+#define GQSPI_LPBK_DLY_ADJ_DLY_1	0x1
+#define GQSPI_LPBK_DLY_ADJ_DLY_1_SHIFT	3
+#define GQSPI_LPBK_DLY_ADJ_DLY_0	0x3
+#define GQSPI_USE_DATA_DLY		0x1
+#define GQSPI_USE_DATA_DLY_SHIFT	31
+#define GQSPI_DATA_DLY_ADJ_VALUE	0x2
+#define GQSPI_DATA_DLY_ADJ_SHIFT	28
+#define TAP_DLY_BYPASS_LQSPI_RX_VALUE	0x1
+#define TAP_DLY_BYPASS_LQSPI_RX_SHIFT	2
+
+/* set to differentiate versal from zynqmp, 1=versal, 0=zynqmp */
+#define QSPI_QUIRK_HAS_TAPDELAY	BIT(0)
+
+#define GQSPI_FREQ_37_5MHZ	37500000
+#define GQSPI_FREQ_40MHZ	40000000
+#define GQSPI_FREQ_100MHZ	100000000
+#define GQSPI_FREQ_150MHZ	150000000
+#define IOU_TAPDLY_BYPASS_MASK	0x7
 
 #define SPI_AUTOSUSPEND_TIMEOUT		3000
 enum mode_type {GQSPI_MODE_IO, GQSPI_MODE_DMA};
 
+/**
+ * struct zynq_platform_data - zynqmp qspi platform data structure
+ * @quirks:	Flags is used to identify the platform
+ */
+struct qspi_platform_data {
+	u32 quirks;
+};
+
 /**
  * struct zynqmp_qspi - Defines qspi driver instance
  * @regs:		Virtual address of the QSPI controller registers
@@ -152,12 +188,16 @@ enum mode_type {GQSPI_MODE_IO, GQSPI_MODE_DMA};
  * @genfifobus:		Used to select the upper or lower bus
  * @dma_rx_bytes:	Remaining bytes to receive by DMA mode
  * @dma_addr:		DMA address after mapping the kernel buffer
+ * @tx_bus_width:	Used to represent number of data wires for tx
+ * @rx_bus_width:	Used to represent number of data wires
  * @genfifoentry:	Used for storing the genfifoentry instruction.
  * @mode:		Defines the mode in which QSPI is operating
+ * @speed_hz:		Current SPI bus clock speed in hz
+ * @io_mode:		Defines the operating mode, either IO or dma
+ * @has_tapdelay:	Used for tapdelay register available in qspi
  * @data_completion:	completion structure
  */
 struct zynqmp_qspi {
-	struct spi_controller *ctlr;
 	void __iomem *regs;
 	struct clk *refclk;
 	struct clk *pclk;
@@ -171,8 +211,13 @@ struct zynqmp_qspi {
 	u32 genfifobus;
 	u32 dma_rx_bytes;
 	dma_addr_t dma_addr;
+	u32 rx_bus_width;
+	u32 tx_bus_width;
 	u32 genfifoentry;
 	enum mode_type mode;
+	u32 speed_hz;
+	bool io_mode;
+	bool has_tapdelay;
 	struct completion data_completion;
 	struct mutex op_lock;
 };
@@ -247,6 +292,70 @@ static void zynqmp_gqspi_selectslave(struct zynqmp_qspi *instanceptr,
 	}
 }
 
+/**
+ * zynqmp_qspi_set_tapdelay:	To configure qspi tap delays
+ * @xqspi:		Pointer to the zynqmp_qspi structure
+ * @baudrateval:	Buadrate to configure
+ */
+static void zynqmp_qspi_set_tapdelay(struct zynqmp_qspi *xqspi, u32 baudrateval)
+{
+	u32 tapdlybypass = 0, lpbkdlyadj = 0, datadlyadj = 0, clk_rate;
+	u32 reqhz = 0;
+
+	clk_rate = clk_get_rate(xqspi->refclk);
+	reqhz = (clk_rate / (GQSPI_BAUD_DIV_SHIFT << baudrateval));
+
+	if (!xqspi->has_tapdelay) {
+		if (reqhz <= GQSPI_FREQ_40MHZ) {
+			zynqmp_pm_set_tapdelay_bypass(
+					   PM_TAPDELAY_QSPI,
+					   PM_TAPDELAY_BYPASS_ENABLE);
+		} else if (reqhz <= GQSPI_FREQ_100MHZ) {
+			zynqmp_pm_set_tapdelay_bypass(
+					   PM_TAPDELAY_QSPI,
+					   PM_TAPDELAY_BYPASS_ENABLE);
+			lpbkdlyadj |= (GQSPI_LPBK_DLY_ADJ_USE_LPBK_MASK);
+			datadlyadj |= ((GQSPI_USE_DATA_DLY <<
+					GQSPI_USE_DATA_DLY_SHIFT)
+					| (GQSPI_DATA_DLY_ADJ_VALUE <<
+						GQSPI_DATA_DLY_ADJ_SHIFT));
+		} else if (reqhz <= GQSPI_FREQ_150MHZ) {
+			lpbkdlyadj |= GQSPI_LPBK_DLY_ADJ_USE_LPBK_MASK;
+		}
+	} else {
+		if (reqhz <= GQSPI_FREQ_37_5MHZ) {
+			tapdlybypass |= (TAP_DLY_BYPASS_LQSPI_RX_VALUE <<
+					TAP_DLY_BYPASS_LQSPI_RX_SHIFT);
+		} else if (reqhz <= GQSPI_FREQ_100MHZ) {
+			tapdlybypass |= (TAP_DLY_BYPASS_LQSPI_RX_VALUE <<
+					TAP_DLY_BYPASS_LQSPI_RX_SHIFT);
+			lpbkdlyadj |= (GQSPI_LPBK_DLY_ADJ_USE_LPBK_MASK);
+			datadlyadj |= (GQSPI_USE_DATA_DLY <<
+					GQSPI_USE_DATA_DLY_SHIFT);
+		} else if (reqhz <= GQSPI_FREQ_150MHZ) {
+			lpbkdlyadj |= (GQSPI_LPBK_DLY_ADJ_USE_LPBK_MASK
+				       | (GQSPI_LPBK_DLY_ADJ_DLY_1 <<
+					       GQSPI_LPBK_DLY_ADJ_DLY_1_SHIFT));
+		}
+		zynqmp_gqspi_write(xqspi,
+				   IOU_TAPDLY_BYPASS_OFST, tapdlybypass);
+	}
+
+	zynqmp_gqspi_write(xqspi, GQSPI_LPBK_DLY_ADJ_OFST, lpbkdlyadj);
+	zynqmp_gqspi_write(xqspi, GQSPI_DATA_DLY_ADJ_OFST, datadlyadj);
+}
+
+static u32 zynqmp_disable_intr(struct zynqmp_qspi *xqspi)
+{
+	u32 value;
+
+	zynqmp_gqspi_write(xqspi, GQSPI_IDR_OFST, GQSPI_ISR_IDR_MASK);
+	value = zynqmp_gqspi_read(xqspi, GQSPI_IMASK_OFST);
+	zynqmp_gqspi_write(xqspi, GQSPI_IDR_OFST, GQSPI_ISR_IDR_MASK);
+
+	return value;
+}
+
 /**
  * zynqmp_qspi_init_hw - Initialize the hardware
  * @xqspi:	Pointer to the zynqmp_qspi structure
@@ -268,13 +377,13 @@ static void zynqmp_gqspi_selectslave(struct zynqmp_qspi *instanceptr,
 static void zynqmp_qspi_init_hw(struct zynqmp_qspi *xqspi)
 {
 	u32 config_reg;
+	u32 baud_rate_val = 0;
+	ulong clk_rate = clk_get_rate(xqspi->refclk);
 
 	/* Select the GQSPI mode */
 	zynqmp_gqspi_write(xqspi, GQSPI_SEL_OFST, GQSPI_SEL_MASK);
 	/* Clear and disable interrupts */
-	zynqmp_gqspi_write(xqspi, GQSPI_ISR_OFST,
-			   zynqmp_gqspi_read(xqspi, GQSPI_ISR_OFST) |
-			   GQSPI_ISR_WR_TO_CLR_MASK);
+	zynqmp_disable_intr(xqspi);
 	/* Clear the DMA STS */
 	zynqmp_gqspi_write(xqspi, GQSPI_QSPIDMA_DST_I_STS_OFST,
 			   zynqmp_gqspi_read(xqspi,
@@ -313,9 +422,11 @@ static void zynqmp_qspi_init_hw(struct zynqmp_qspi *xqspi)
 			   GQSPI_FIFO_CTRL_RST_TX_FIFO_MASK |
 			   GQSPI_FIFO_CTRL_RST_GEN_FIFO_MASK);
 	/* Set by default to allow for high frequencies */
-	zynqmp_gqspi_write(xqspi, GQSPI_LPBK_DLY_ADJ_OFST,
-			   zynqmp_gqspi_read(xqspi, GQSPI_LPBK_DLY_ADJ_OFST) |
-			   GQSPI_LPBK_DLY_ADJ_USE_LPBK_MASK);
+	while ((baud_rate_val < GQSPI_BAUD_DIV_MAX) &&
+	       (clk_rate /
+		(GQSPI_BAUD_DIV_SHIFT << baud_rate_val)) > xqspi->speed_hz)
+		baud_rate_val++;
+	zynqmp_qspi_set_tapdelay(xqspi, baud_rate_val);
 	/* Reset thresholds */
 	zynqmp_gqspi_write(xqspi, GQSPI_TX_THRESHOLD_OFST,
 			   GQSPI_TX_FIFO_THRESHOLD_RESET_VAL);
@@ -326,11 +437,11 @@ static void zynqmp_qspi_init_hw(struct zynqmp_qspi *xqspi)
 	zynqmp_gqspi_selectslave(xqspi,
 				 GQSPI_SELECT_FLASH_CS_LOWER,
 				 GQSPI_SELECT_FLASH_BUS_LOWER);
-	/* Initialize DMA */
-	zynqmp_gqspi_write(xqspi,
-			   GQSPI_QSPIDMA_DST_CTRL_OFST,
-			   GQSPI_QSPIDMA_DST_CTRL_RESET_VAL);
-
+	if (!xqspi->io_mode)
+		/* Initialize DMA */
+		zynqmp_gqspi_write(xqspi,
+				   GQSPI_QSPIDMA_DST_CTRL_OFST,
+				   GQSPI_QSPIDMA_DST_CTRL_RESET_VAL);
 	/* Enable the GQSPI */
 	zynqmp_gqspi_write(xqspi, GQSPI_EN_OFST, GQSPI_EN_MASK);
 }
@@ -361,11 +472,22 @@ static void zynqmp_qspi_chipselect(struct spi_device *qspi, bool is_high)
 	u32 genfifoentry = 0, statusreg;
 
 	genfifoentry |= GQSPI_GENFIFO_MODE_SPI;
+	if (qspi->master->flags & SPI_MASTER_BOTH_CS) {
+		zynqmp_gqspi_selectslave(xqspi,
+					 GQSPI_SELECT_FLASH_CS_BOTH,
+					 GQSPI_SELECT_FLASH_BUS_BOTH);
+	} else if (qspi->master->flags & SPI_MASTER_U_PAGE) {
+		zynqmp_gqspi_selectslave(xqspi,
+					 GQSPI_SELECT_FLASH_CS_UPPER,
+					 GQSPI_SELECT_FLASH_BUS_LOWER);
+	} else {
+		zynqmp_gqspi_selectslave(xqspi,
+					 GQSPI_SELECT_FLASH_CS_LOWER,
+					 GQSPI_SELECT_FLASH_BUS_LOWER);
+	}
 
+	genfifoentry |= xqspi->genfifobus;
 	if (!is_high) {
-		xqspi->genfifobus = GQSPI_GENFIFO_BUS_LOWER;
-		xqspi->genfifocs = GQSPI_GENFIFO_CS_LOWER;
-		genfifoentry |= xqspi->genfifobus;
 		genfifoentry |= xqspi->genfifocs;
 		genfifoentry |= GQSPI_GENFIFO_CS_SETUP;
 	} else {
@@ -448,30 +570,38 @@ static int zynqmp_qspi_config_op(struct zynqmp_qspi *xqspi,
 				 struct spi_device *qspi)
 {
 	ulong clk_rate;
-	u32 config_reg, baud_rate_val = 0;
+	u32 config_reg, req_hz, baud_rate_val = 0;
 
-	/* Set the clock frequency */
-	/* If req_hz == 0, default to lowest speed */
-	clk_rate = clk_get_rate(xqspi->refclk);
+	req_hz = qspi->max_speed_hz;
 
-	while ((baud_rate_val < GQSPI_BAUD_DIV_MAX) &&
-	       (clk_rate /
-		(GQSPI_BAUD_DIV_SHIFT << baud_rate_val)) > qspi->max_speed_hz)
-		baud_rate_val++;
+	if (xqspi->speed_hz != req_hz) {
+		/* Set the clock frequency */
+		/* If req_hz == 0, default to lowest speed */
+		clk_rate = clk_get_rate(xqspi->refclk);
 
-	config_reg = zynqmp_gqspi_read(xqspi, GQSPI_CONFIG_OFST);
+		while ((baud_rate_val < GQSPI_BAUD_DIV_MAX) &&
+		       (clk_rate /
+			(GQSPI_BAUD_DIV_SHIFT << baud_rate_val)) > req_hz)
+			baud_rate_val++;
 
-	/* Set the QSPI clock phase and clock polarity */
-	config_reg &= (~GQSPI_CFG_CLK_PHA_MASK) & (~GQSPI_CFG_CLK_POL_MASK);
+		config_reg = zynqmp_gqspi_read(xqspi, GQSPI_CONFIG_OFST);
 
-	if (qspi->mode & SPI_CPHA)
-		config_reg |= GQSPI_CFG_CLK_PHA_MASK;
-	if (qspi->mode & SPI_CPOL)
-		config_reg |= GQSPI_CFG_CLK_POL_MASK;
+		/* Set the QSPI clock phase and clock polarity */
+		config_reg &= (~GQSPI_CFG_CLK_PHA_MASK) &
+			(~GQSPI_CFG_CLK_POL_MASK);
+
+		if (qspi->mode & SPI_CPHA)
+			config_reg |= GQSPI_CFG_CLK_PHA_MASK;
+		if (qspi->mode & SPI_CPOL)
+			config_reg |= GQSPI_CFG_CLK_POL_MASK;
+		config_reg &= ~GQSPI_CFG_BAUD_RATE_DIV_MASK;
+		config_reg |= (baud_rate_val << GQSPI_CFG_BAUD_RATE_DIV_SHIFT);
+		zynqmp_gqspi_write(xqspi, GQSPI_CONFIG_OFST, config_reg);
+		xqspi->speed_hz = clk_rate / (GQSPI_BAUD_DIV_SHIFT <<
+				baud_rate_val);
+		zynqmp_qspi_set_tapdelay(xqspi, baud_rate_val);
+	}
 
-	config_reg &= ~GQSPI_CFG_BAUD_RATE_DIV_MASK;
-	config_reg |= (baud_rate_val << GQSPI_CFG_BAUD_RATE_DIV_SHIFT);
-	zynqmp_gqspi_write(xqspi, GQSPI_CONFIG_OFST, config_reg);
 	return 0;
 }
 
@@ -488,10 +618,24 @@ static int zynqmp_qspi_setup_op(struct spi_device *qspi)
 {
 	struct spi_controller *ctlr = qspi->master;
 	struct zynqmp_qspi *xqspi = spi_controller_get_devdata(ctlr);
+	struct device *dev = &ctlr->dev;
+	int ret;
 
 	if (ctlr->busy)
 		return -EBUSY;
 
+	ret = clk_enable(xqspi->refclk);
+	if (ret) {
+		dev_err(dev, "Cannot enable device clock.\n");
+		return ret;
+	}
+
+	ret = clk_enable(xqspi->pclk);
+	if (ret) {
+		dev_err(dev, "Cannot enable APB clock.\n");
+		clk_disable(xqspi->refclk);
+		return ret;
+	}
 	zynqmp_gqspi_write(xqspi, GQSPI_EN_OFST, GQSPI_EN_MASK);
 
 	return 0;
@@ -508,18 +652,21 @@ static void zynqmp_qspi_filltxfifo(struct zynqmp_qspi *xqspi, int size)
 {
 	u32 count = 0, intermediate;
 
-	while ((xqspi->bytes_to_transfer > 0) && (count < size) && (xqspi->txbuf)) {
-		memcpy(&intermediate, xqspi->txbuf, 4);
-		zynqmp_gqspi_write(xqspi, GQSPI_TXD_OFST, intermediate);
-
-		if (xqspi->bytes_to_transfer >= 4) {
-			xqspi->txbuf += 4;
-			xqspi->bytes_to_transfer -= 4;
-		} else {
-			xqspi->txbuf += xqspi->bytes_to_transfer;
-			xqspi->bytes_to_transfer = 0;
-		}
-		count++;
+	while ((xqspi->bytes_to_transfer > 0) && (count < size) &&
+	       (xqspi->txbuf)) {
+                if (xqspi->bytes_to_transfer >= 4) {
+                        memcpy(&intermediate, xqspi->txbuf, 4);
+                        xqspi->txbuf += 4;
+                        xqspi->bytes_to_transfer -= 4;
+                        count += 4;
+                } else {
+                        memcpy(&intermediate, xqspi->txbuf,
+                               xqspi->bytes_to_transfer);
+                        xqspi->txbuf += xqspi->bytes_to_transfer;
+                        xqspi->bytes_to_transfer = 0;
+                        count += xqspi->bytes_to_transfer;
+                }
+                zynqmp_gqspi_write(xqspi, GQSPI_TXD_OFST, intermediate);
 	}
 }
 
@@ -576,7 +723,6 @@ static void zynqmp_qspi_fillgenfifo(struct zynqmp_qspi *xqspi, u8 nbits,
 		else
 			transfer_len = xqspi->bytes_to_receive;
 	} else {
-		/* Sending dummy circles here */
 		genfifoentry &= ~(GQSPI_GENFIFO_TX | GQSPI_GENFIFO_RX);
 		genfifoentry |= GQSPI_GENFIFO_DATA_XFER;
 		transfer_len = xqspi->bytes_to_transfer;
@@ -703,49 +849,56 @@ static irqreturn_t zynqmp_qspi_irq(int irq, void *dev_id)
 		zynqmp_gqspi_write(xqspi, GQSPI_QSPIDMA_DST_I_STS_OFST,
 				   dma_status);
 	}
-
-	if (mask & GQSPI_ISR_TXNOT_FULL_MASK) {
-		zynqmp_qspi_filltxfifo(xqspi, GQSPI_TX_FIFO_FILL);
-		ret = IRQ_HANDLED;
-	}
-
 	if (dma_status & GQSPI_QSPIDMA_DST_I_STS_DONE_MASK) {
 		zynqmp_process_dma_irq(xqspi);
 		ret = IRQ_HANDLED;
-	} else if (!(mask & GQSPI_IER_RXEMPTY_MASK) &&
-			(mask & GQSPI_IER_GENFIFOEMPTY_MASK)) {
+	} else if ((mask & GQSPI_IER_RXNEMPTY_MASK)) {
+		zynqmp_qspi_readrxfifo(xqspi, GQSPI_RX_FIFO_FILL);
+		ret = IRQ_HANDLED;
+	}
+	if (!(mask & GQSPI_IER_RXEMPTY_MASK) &&
+	    (mask & GQSPI_IER_GENFIFOEMPTY_MASK)) {
 		zynqmp_qspi_readrxfifo(xqspi, GQSPI_RX_FIFO_FILL);
 		ret = IRQ_HANDLED;
 	}
 
 	if (xqspi->bytes_to_receive == 0 && xqspi->bytes_to_transfer == 0 &&
 	    ((status & GQSPI_IRQ_MASK) == GQSPI_IRQ_MASK)) {
-		zynqmp_gqspi_write(xqspi, GQSPI_IDR_OFST, GQSPI_ISR_IDR_MASK);
-		complete(&xqspi->data_completion);
+		goto transfer_complete;
+	}
+	if (mask & GQSPI_ISR_TXNOT_FULL_MASK) {
+		zynqmp_qspi_filltxfifo(xqspi, GQSPI_TX_FIFO_FILL);
 		ret = IRQ_HANDLED;
 	}
+
 	return ret;
+
+transfer_complete:
+	zynqmp_disable_intr(xqspi);
+	complete(&xqspi->data_completion);
+	return IRQ_HANDLED;
 }
 
 /**
  * zynqmp_qspi_setuprxdma - This function sets up the RX DMA operation
  * @xqspi:	xqspi is a pointer to the GQSPI instance.
  */
-static int zynqmp_qspi_setuprxdma(struct zynqmp_qspi *xqspi)
+static void zynqmp_qspi_setuprxdma(struct zynqmp_qspi *xqspi)
 {
 	u32 rx_bytes, rx_rem, config_reg;
 	dma_addr_t addr;
 	u64 dma_align =  (u64)(uintptr_t)xqspi->rxbuf;
 
-	if (xqspi->bytes_to_receive < 8 ||
-	    ((dma_align & GQSPI_DMA_UNALIGN) != 0x0)) {
+	if ((xqspi->bytes_to_receive < 8 || xqspi->io_mode) ||
+	    ((dma_align & GQSPI_DMA_UNALIGN) != 0x0) ||
+	    is_vmalloc_addr(xqspi->rxbuf)) {
 		/* Setting to IO mode */
 		config_reg = zynqmp_gqspi_read(xqspi, GQSPI_CONFIG_OFST);
 		config_reg &= ~GQSPI_CFG_MODE_EN_MASK;
 		zynqmp_gqspi_write(xqspi, GQSPI_CONFIG_OFST, config_reg);
 		xqspi->mode = GQSPI_MODE_IO;
 		xqspi->dma_rx_bytes = 0;
-		return 0;
+		return;
 	}
 
 	rx_rem = xqspi->bytes_to_receive % 4;
@@ -753,10 +906,8 @@ static int zynqmp_qspi_setuprxdma(struct zynqmp_qspi *xqspi)
 
 	addr = dma_map_single(xqspi->dev, (void *)xqspi->rxbuf,
 			      rx_bytes, DMA_FROM_DEVICE);
-	if (dma_mapping_error(xqspi->dev, addr)) {
+	if (dma_mapping_error(xqspi->dev, addr))
 		dev_err(xqspi->dev, "ERR:rxdma:memory not mapped\n");
-		return -ENOMEM;
-	}
 
 	xqspi->dma_rx_bytes = rx_bytes;
 	xqspi->dma_addr = addr;
@@ -777,8 +928,6 @@ static int zynqmp_qspi_setuprxdma(struct zynqmp_qspi *xqspi)
 
 	/* Write the number of bytes to transfer */
 	zynqmp_gqspi_write(xqspi, GQSPI_QSPIDMA_DST_SIZE_OFST, rx_bytes);
-
-	return 0;
 }
 
 /**
@@ -815,17 +964,11 @@ static void zynqmp_qspi_write_op(struct zynqmp_qspi *xqspi, u8 tx_nbits,
  * @genfifoentry:	genfifoentry is pointer to the variable in which
  *			GENFIFO	mask is returned to calling function
  */
-static int zynqmp_qspi_read_op(struct zynqmp_qspi *xqspi, u8 rx_nbits,
+static void zynqmp_qspi_read_op(struct zynqmp_qspi *xqspi, u8 rx_nbits,
 				u32 genfifoentry)
 {
-	int ret;
-
-	ret = zynqmp_qspi_setuprxdma(xqspi);
-	if (ret)
-		return ret;
+	zynqmp_qspi_setuprxdma(xqspi);
 	zynqmp_qspi_fillgenfifo(xqspi, rx_nbits, genfifoentry);
-
-	return 0;
 }
 
 /**
@@ -838,13 +981,10 @@ static int zynqmp_qspi_read_op(struct zynqmp_qspi *xqspi, u8 rx_nbits,
  */
 static int __maybe_unused zynqmp_qspi_suspend(struct device *dev)
 {
-	struct zynqmp_qspi *xqspi = dev_get_drvdata(dev);
-	struct spi_controller *ctlr = xqspi->ctlr;
-	int ret;
+	struct spi_controller *ctlr = dev_get_drvdata(dev);
+	struct zynqmp_qspi *xqspi = spi_controller_get_devdata(ctlr);
 
-	ret = spi_controller_suspend(ctlr);
-	if (ret)
-		return ret;
+	spi_controller_suspend(ctlr);
 
 	zynqmp_gqspi_write(xqspi, GQSPI_EN_OFST, 0x0);
 
@@ -862,13 +1002,28 @@ static int __maybe_unused zynqmp_qspi_suspend(struct device *dev)
  */
 static int __maybe_unused zynqmp_qspi_resume(struct device *dev)
 {
-	struct zynqmp_qspi *xqspi = dev_get_drvdata(dev);
-	struct spi_controller *ctlr = xqspi->ctlr;
+	struct spi_controller *ctlr = dev_get_drvdata(dev);
+	struct zynqmp_qspi *xqspi = spi_controller_get_devdata(ctlr);
+	int ret = 0;
 
-	zynqmp_gqspi_write(xqspi, GQSPI_EN_OFST, GQSPI_EN_MASK);
+	ret = clk_enable(xqspi->pclk);
+	if (ret) {
+		dev_err(dev, "Cannot enable APB clock.\n");
+		return ret;
+	}
 
+	ret = clk_enable(xqspi->refclk);
+	if (ret) {
+		dev_err(dev, "Cannot enable device clock.\n");
+		clk_disable(xqspi->pclk);
+		return ret;
+	}
+
+	zynqmp_qspi_init_hw(xqspi);
 	spi_controller_resume(ctlr);
 
+	clk_disable(xqspi->refclk);
+	clk_disable(xqspi->pclk);
 	return 0;
 }
 
@@ -882,10 +1037,11 @@ static int __maybe_unused zynqmp_qspi_resume(struct device *dev)
  */
 static int __maybe_unused zynqmp_runtime_suspend(struct device *dev)
 {
-	struct zynqmp_qspi *xqspi = dev_get_drvdata(dev);
+	struct spi_controller *ctlr = dev_get_drvdata(dev);
+	struct zynqmp_qspi *xqspi = spi_controller_get_devdata(ctlr);
 
-	clk_disable_unprepare(xqspi->refclk);
-	clk_disable_unprepare(xqspi->pclk);
+	clk_disable(xqspi->refclk);
+	clk_disable(xqspi->pclk);
 
 	return 0;
 }
@@ -900,19 +1056,20 @@ static int __maybe_unused zynqmp_runtime_suspend(struct device *dev)
  */
 static int __maybe_unused zynqmp_runtime_resume(struct device *dev)
 {
-	struct zynqmp_qspi *xqspi = dev_get_drvdata(dev);
+	struct spi_controller *ctlr = dev_get_drvdata(dev);
+	struct zynqmp_qspi *xqspi = spi_controller_get_devdata(ctlr);
 	int ret;
 
-	ret = clk_prepare_enable(xqspi->pclk);
+	ret = clk_enable(xqspi->pclk);
 	if (ret) {
 		dev_err(dev, "Cannot enable APB clock.\n");
 		return ret;
 	}
 
-	ret = clk_prepare_enable(xqspi->refclk);
+	ret = clk_enable(xqspi->refclk);
 	if (ret) {
 		dev_err(dev, "Cannot enable device clock.\n");
-		clk_disable_unprepare(xqspi->pclk);
+		clk_disable(xqspi->pclk);
 		return ret;
 	}
 
@@ -936,9 +1093,8 @@ static int zynqmp_qspi_exec_op(struct spi_mem *mem,
 	struct zynqmp_qspi *xqspi = spi_controller_get_devdata
 				    (mem->spi->master);
 	int err = 0, i;
+	u8 *tmpbuf;
 	u32 genfifoentry = 0;
-	u16 opcode = op->cmd.opcode;
-	u64 opaddr;
 
 	dev_dbg(xqspi->dev, "cmd:%#x mode:%d.%d.%d.%d\n",
 		op->cmd.opcode, op->cmd.buswidth, op->addr.buswidth,
@@ -951,8 +1107,12 @@ static int zynqmp_qspi_exec_op(struct spi_mem *mem,
 	genfifoentry |= xqspi->genfifobus;
 
 	if (op->cmd.opcode) {
+		tmpbuf = kzalloc(op->cmd.nbytes, GFP_KERNEL | GFP_DMA);
+		if (!tmpbuf)
+			return -ENOMEM;
+		tmpbuf[0] = op->cmd.opcode;
 		reinit_completion(&xqspi->data_completion);
-		xqspi->txbuf = &opcode;
+		xqspi->txbuf = tmpbuf;
 		xqspi->rxbuf = NULL;
 		xqspi->bytes_to_transfer = op->cmd.nbytes;
 		xqspi->bytes_to_receive = 0;
@@ -961,17 +1121,19 @@ static int zynqmp_qspi_exec_op(struct spi_mem *mem,
 				   zynqmp_gqspi_read(xqspi, GQSPI_CONFIG_OFST) |
 				   GQSPI_CFG_START_GEN_FIFO_MASK);
 		zynqmp_gqspi_write(xqspi, GQSPI_IER_OFST,
+				   GQSPI_IER_TXEMPTY_MASK |
 				   GQSPI_IER_GENFIFOEMPTY_MASK |
 				   GQSPI_IER_TXNOT_FULL_MASK);
 		if (!wait_for_completion_timeout
 		    (&xqspi->data_completion, msecs_to_jiffies(1000))) {
 			err = -ETIMEDOUT;
+			kfree(tmpbuf);
 			goto return_err;
 		}
+		kfree(tmpbuf);
 	}
 
 	if (op->addr.nbytes) {
-		xqspi->txbuf = &opaddr;
 		for (i = 0; i < op->addr.nbytes; i++) {
 			*(((u8 *)xqspi->txbuf) + i) = op->addr.val >>
 					(8 * (op->addr.nbytes - i - 1));
@@ -1002,13 +1164,14 @@ static int zynqmp_qspi_exec_op(struct spi_mem *mem,
 		xqspi->rxbuf = NULL;
 		/*
 		 * xqspi->bytes_to_transfer here represents the dummy circles
-		 * which need to be sent.
+		 * per data line.
 		 */
 		xqspi->bytes_to_transfer = op->dummy.nbytes * 8 / op->dummy.buswidth;
 		xqspi->bytes_to_receive = 0;
 		/*
-		 * Using op->data.buswidth instead of op->dummy.buswidth here because
-		 * we need to use it to configure the correct SPI mode.
+		 * Using op->data.buswidth instead of op->dummy.buswidth since
+		 * the specification requires that the dummy.buswidth should
+		 * be the same as data.buswidth.
 		 */
 		zynqmp_qspi_write_op(xqspi, op->data.buswidth,
 				     genfifoentry);
@@ -1018,6 +1181,11 @@ static int zynqmp_qspi_exec_op(struct spi_mem *mem,
 	}
 
 	if (op->data.nbytes) {
+		if (mem->spi->master->flags & SPI_MASTER_DATA_STRIPE) {
+			if (update_stripe(op)) {
+				genfifoentry |= GQSPI_GENFIFO_STRIPE;
+			}
+		}
 		reinit_completion(&xqspi->data_completion);
 		if (op->data.dir == SPI_MEM_DATA_OUT) {
 			xqspi->txbuf = (u8 *)op->data.buf.out;
@@ -1039,11 +1207,8 @@ static int zynqmp_qspi_exec_op(struct spi_mem *mem,
 			xqspi->rxbuf = (u8 *)op->data.buf.in;
 			xqspi->bytes_to_receive = op->data.nbytes;
 			xqspi->bytes_to_transfer = 0;
-			err = zynqmp_qspi_read_op(xqspi, op->data.buswidth,
+			zynqmp_qspi_read_op(xqspi, op->data.buswidth,
 					    genfifoentry);
-			if (err)
-				goto return_err;
-
 			zynqmp_gqspi_write(xqspi, GQSPI_CONFIG_OFST,
 					   zynqmp_gqspi_read
 					   (xqspi, GQSPI_CONFIG_OFST) |
@@ -1060,7 +1225,7 @@ static int zynqmp_qspi_exec_op(struct spi_mem *mem,
 			}
 		}
 		if (!wait_for_completion_timeout
-		    (&xqspi->data_completion, msecs_to_jiffies(1000)))
+		    (&xqspi->data_completion, msecs_to_jiffies(1000000)))
 			err = -ETIMEDOUT;
 	}
 
@@ -1072,12 +1237,35 @@ static int zynqmp_qspi_exec_op(struct spi_mem *mem,
 	return err;
 }
 
+static int __maybe_unused zynqmp_runtime_idle(struct device *dev)
+{
+	struct spi_controller *ctlr = dev_get_drvdata(dev);
+	struct zynqmp_qspi *xqspi = spi_controller_get_devdata(ctlr);
+	u32 value;
+
+	value = zynqmp_gqspi_read(xqspi, GQSPI_EN_OFST);
+	if (value)
+		return -EBUSY;
+
+	return 0;
+}
+
 static const struct dev_pm_ops zynqmp_qspi_dev_pm_ops = {
 	SET_RUNTIME_PM_OPS(zynqmp_runtime_suspend,
-			   zynqmp_runtime_resume, NULL)
+			   zynqmp_runtime_resume, zynqmp_runtime_idle)
 	SET_SYSTEM_SLEEP_PM_OPS(zynqmp_qspi_suspend, zynqmp_qspi_resume)
 };
 
+static const struct qspi_platform_data versal_qspi_def = {
+	.quirks = QSPI_QUIRK_HAS_TAPDELAY,
+};
+
+static const struct of_device_id zynqmp_qspi_of_match[] = {
+	{ .compatible = "xlnx,zynqmp-qspi-1.0"},
+	{ .compatible = "xlnx,versal-qspi-1.0", .data = &versal_qspi_def },
+	{ /* End of table */ }
+};
+
 static const struct spi_controller_mem_ops zynqmp_qspi_mem_ops = {
 	.exec_op = zynqmp_qspi_exec_op,
 };
@@ -1096,6 +1284,11 @@ static int zynqmp_qspi_probe(struct platform_device *pdev)
 	struct spi_controller *ctlr;
 	struct zynqmp_qspi *xqspi;
 	struct device *dev = &pdev->dev;
+	struct device_node *nc;
+	const struct of_device_id *match;
+	u32 num_cs;
+	u32 rx_bus_width;
+	u32 tx_bus_width;
 	struct device_node *np = dev->of_node;
 
 	ctlr = spi_alloc_master(&pdev->dev, sizeof(*xqspi));
@@ -1104,9 +1297,15 @@ static int zynqmp_qspi_probe(struct platform_device *pdev)
 
 	xqspi = spi_controller_get_devdata(ctlr);
 	xqspi->dev = dev;
-	xqspi->ctlr = ctlr;
-	platform_set_drvdata(pdev, xqspi);
+	platform_set_drvdata(pdev, ctlr);
 
+	match = of_match_node(zynqmp_qspi_of_match, pdev->dev.of_node);
+	if (match) {
+		const struct qspi_platform_data *p_data = match->data;
+
+		if (p_data && (p_data->quirks & QSPI_QUIRK_HAS_TAPDELAY))
+			xqspi->has_tapdelay = true;
+	}
 	xqspi->regs = devm_platform_ioremap_resource(pdev, 0);
 	if (IS_ERR(xqspi->regs)) {
 		ret = PTR_ERR(xqspi->regs);
@@ -1120,11 +1319,13 @@ static int zynqmp_qspi_probe(struct platform_device *pdev)
 		goto remove_master;
 	}
 
+	init_completion(&xqspi->data_completion);
+
 	xqspi->refclk = devm_clk_get(&pdev->dev, "ref_clk");
 	if (IS_ERR(xqspi->refclk)) {
 		dev_err(dev, "ref_clk clock not found.\n");
 		ret = PTR_ERR(xqspi->refclk);
-		goto remove_master;
+		goto clk_dis_pclk;
 	}
 
 	ret = clk_prepare_enable(xqspi->pclk);
@@ -1139,14 +1340,19 @@ static int zynqmp_qspi_probe(struct platform_device *pdev)
 		goto clk_dis_pclk;
 	}
 
-	init_completion(&xqspi->data_completion);
-
 	mutex_init(&xqspi->op_lock);
 
 	pm_runtime_use_autosuspend(&pdev->dev);
 	pm_runtime_set_autosuspend_delay(&pdev->dev, SPI_AUTOSUSPEND_TIMEOUT);
 	pm_runtime_set_active(&pdev->dev);
 	pm_runtime_enable(&pdev->dev);
+
+	if (of_property_read_bool(pdev->dev.of_node, "has-io-mode"))
+		xqspi->io_mode = true;
+
+	ctlr->max_speed_hz = clk_get_rate(xqspi->refclk) / 2;
+	xqspi->speed_hz = ctlr->max_speed_hz;
+
 	/* QSPI controller initializations */
 	zynqmp_qspi_init_hw(xqspi);
 
@@ -1155,6 +1361,7 @@ static int zynqmp_qspi_probe(struct platform_device *pdev)
 	xqspi->irq = platform_get_irq(pdev, 0);
 	if (xqspi->irq <= 0) {
 		ret = -ENXIO;
+		dev_err(dev, "irq resource not found\n");
 		goto clk_dis_all;
 	}
 	ret = devm_request_irq(&pdev->dev, xqspi->irq, zynqmp_qspi_irq,
@@ -1165,19 +1372,46 @@ static int zynqmp_qspi_probe(struct platform_device *pdev)
 		goto clk_dis_all;
 	}
 
-	ret = dma_set_mask(&pdev->dev, DMA_BIT_MASK(44));
+	xqspi->rx_bus_width = GQSPI_RX_BUS_WIDTH_SINGLE;
+	for_each_available_child_of_node(pdev->dev.of_node, nc) {
+		ret = of_property_read_u32(nc, "spi-rx-bus-width",
+					   &rx_bus_width);
+		if (!ret) {
+			xqspi->rx_bus_width = rx_bus_width;
+			break;
+		}
+	}
 	if (ret)
-		goto clk_dis_all;
+		dev_err(dev, "rx bus width not found\n");
+
+	xqspi->tx_bus_width = GQSPI_TX_BUS_WIDTH_SINGLE;
+	for_each_available_child_of_node(pdev->dev.of_node, nc) {
+		ret = of_property_read_u32(nc, "spi-tx-bus-width",
+					   &tx_bus_width);
+		if (!ret) {
+			xqspi->tx_bus_width = tx_bus_width;
+			break;
+		}
+	}
+	if (ret)
+		dev_err(dev, "tx bus width not found\n");
+
+	ret = of_property_read_u32(pdev->dev.of_node, "num-cs", &num_cs);
+	if (ret < 0)
+		ctlr->num_chipselect = GQSPI_DEFAULT_NUM_CS;
+	else
+		ctlr->num_chipselect = num_cs;
+
+	dma_set_mask(&pdev->dev, DMA_BIT_MASK(44));
 
 	ctlr->bits_per_word_mask = SPI_BPW_MASK(8);
-	ctlr->num_chipselect = GQSPI_DEFAULT_NUM_CS;
 	ctlr->mem_ops = &zynqmp_qspi_mem_ops;
 	ctlr->setup = zynqmp_qspi_setup_op;
-	ctlr->max_speed_hz = clk_get_rate(xqspi->refclk) / 2;
 	ctlr->bits_per_word_mask = SPI_BPW_MASK(8);
 	ctlr->mode_bits = SPI_CPOL | SPI_CPHA | SPI_RX_DUAL | SPI_RX_QUAD |
 			    SPI_TX_DUAL | SPI_TX_QUAD;
 	ctlr->dev.of_node = np;
+	ctlr->auto_runtime_pm = true;
 
 	ret = devm_spi_register_controller(&pdev->dev, ctlr);
 	if (ret) {
@@ -1222,11 +1456,6 @@ static int zynqmp_qspi_remove(struct platform_device *pdev)
 	return 0;
 }
 
-static const struct of_device_id zynqmp_qspi_of_match[] = {
-	{ .compatible = "xlnx,zynqmp-qspi-1.0", },
-	{ /* End of table */ }
-};
-
 MODULE_DEVICE_TABLE(of, zynqmp_qspi_of_match);
 
 static struct platform_driver zynqmp_qspi_driver = {
diff --git a/drivers/spi/spi.c b/drivers/spi/spi.c
index 6ea7b286c..73804c1a2 100644
--- a/drivers/spi/spi.c
+++ b/drivers/spi/spi.c
@@ -2018,6 +2018,9 @@ static int of_spi_parse_dt(struct spi_controller *ctlr, struct spi_device *spi,
 	if (!of_property_read_u32(nc, "spi-max-frequency", &value))
 		spi->max_speed_hz = value;
 
+	/* Multi die flash */
+	if (of_property_read_bool(nc, "multi-die"))
+		spi->multi_die = true;
 	return 0;
 }
 
diff --git a/include/linux/spi/spi-mem.h b/include/linux/spi/spi-mem.h
index 159463cc6..e43ae3b51 100644
--- a/include/linux/spi/spi-mem.h
+++ b/include/linux/spi/spi-mem.h
@@ -55,6 +55,8 @@
 
 #define SPI_MEM_OP_NO_DATA	{ }
 
+#define SPI_MEM_DEV_MAX_ID_LEN		6
+
 /**
  * enum spi_mem_data_dir - describes the direction of a SPI memory data
  *			   transfer from the controller perspective
@@ -101,6 +103,7 @@ struct spi_mem_op {
 		u8 buswidth;
 		u8 dtr : 1;
 		u16 opcode;
+		u8 tune_clk;
 	} cmd;
 
 	struct {
@@ -195,6 +198,8 @@ struct spi_mem {
 	struct spi_device *spi;
 	void *drvpriv;
 	const char *name;
+	u8 device_id[SPI_MEM_DEV_MAX_ID_LEN];
+	struct delayed_work	complete_work;
 };
 
 /**
@@ -338,6 +343,7 @@ bool spi_mem_default_supports_op(struct spi_mem *mem,
 
 int spi_mem_adjust_op_size(struct spi_mem *mem, struct spi_mem_op *op);
 
+bool update_stripe(const struct spi_mem_op *op);
 bool spi_mem_supports_op(struct spi_mem *mem,
 			 const struct spi_mem_op *op);
 
diff --git a/include/linux/spi/spi.h b/include/linux/spi/spi.h
index e1d88630f..cd5adf6a0 100644
--- a/include/linux/spi/spi.h
+++ b/include/linux/spi/spi.h
@@ -144,6 +144,7 @@ extern int spi_delay_exec(struct spi_delay *_delay, struct spi_transfer *xfer);
  *	not using a GPIO line)
  * @word_delay: delay to be inserted between consecutive
  *	words of a transfer
+ * @multi_die: Flash device with multiple dies.
  *
  * @statistics: statistics for the spi_device
  *
@@ -193,6 +194,7 @@ struct spi_device {
 	int			cs_gpio;	/* LEGACY: chip select gpio */
 	struct gpio_desc	*cs_gpiod;	/* chip select gpio desc */
 	struct spi_delay	word_delay; /* inter-word delay */
+	bool			multi_die;	/* flash with multiple dies*/
 
 	/* the statistics */
 	struct spi_statistics	statistics;
@@ -514,6 +516,22 @@ struct spi_controller {
 	/* flag indicating this is a non-devres managed controller */
 	bool			devm_allocated;
 
+#define SPI_MASTER_QUAD_MODE	BIT(6) /* support quad mode */
+	/*
+	 * Controller may support data stripe feature when more than one
+	 * chips are present.
+	 * Setting data stripe will send data in following manner:
+	 * -> even bytes i.e. 0, 2, 4,... are transmitted on lower data bus
+	 * -> odd bytes i.e. 1, 3, 5,.. are transmitted on upper data bus
+	 */
+#define SPI_MASTER_DATA_STRIPE BIT(7)		/* support data stripe */
+	/*
+	 * Controller may support asserting more than one chip select at once.
+	 * This flag will enable that feature.
+	 */
+#define SPI_MASTER_BOTH_CS	BIT(8)		/* assert both chip selects */
+#define SPI_MASTER_U_PAGE	BIT(9)		/* select upper flash */
+#define SPI_DUAL_BYTE_OP	BIT(10)		/* select Dual-Byte opcode */
 	/* flag indicating this is an SPI slave controller */
 	bool			slave;
 
@@ -827,6 +845,7 @@ extern void spi_res_release(struct spi_controller *ctlr,
  * @len: size of rx and tx buffers (in bytes)
  * @speed_hz: Select a speed other than the device default for this
  *      transfer. If 0 the default (from @spi_device) is used.
+ * @dummy: number of dummy cycles.
  * @bits_per_word: select a bits_per_word other than the device default
  *      for this transfer. If 0 the default (from @spi_device) is used.
  * @cs_change: affects chipselect after this transfer completes
@@ -846,6 +865,7 @@ extern void spi_res_release(struct spi_controller *ctlr,
  * @transfer_list: transfers are sequenced through @spi_message.transfers
  * @tx_sg: Scatterlist for transmit, currently not for client use
  * @rx_sg: Scatterlist for receive, currently not for client use
+ * @stripe: true-> enable stripe, false-> disable stripe.
  * @ptp_sts_word_pre: The word (subject to bits_per_word semantics) offset
  *	within @tx_buf for which the SPI device is requesting that the time
  *	snapshot for this transfer begins. Upon completing the SPI transfer,
@@ -953,6 +973,8 @@ struct spi_transfer {
 	struct spi_delay	cs_change_delay;
 	struct spi_delay	word_delay;
 	u32		speed_hz;
+	u32		dummy;
+	bool		stripe;
 
 	u32		effective_speed_hz;
 
